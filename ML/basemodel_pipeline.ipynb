{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_SEED = 69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "387528\n"
     ]
    }
   ],
   "source": [
    "# Check distribution of dataset\n",
    "\n",
    "data = pd.read_csv('Datasets/Cleaned/finetuning_dataset.csv')\n",
    "twitter_data = data[data['source'] == 'Twitter'].sample(frac=0.3, random_state=RANDOM_SEED)\n",
    "other_data = data[data['source'] != 'Twitter']\n",
    "sampled_data = pd.concat([twitter_data, other_data])\n",
    "\n",
    "print(sampled_data['source'].value_counts().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 348775, Evaluation size: 38753\n"
     ]
    }
   ],
   "source": [
    "# Perform train-test split\n",
    "train_df, eval_df = train_test_split(\n",
    "    sampled_data, \n",
    "    test_size=0.1, \n",
    "    stratify=sampled_data['source'],  # Preserve source distribution\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "eval_dataset = Dataset.from_pandas(eval_df)\n",
    "\n",
    "# Inspect the splits\n",
    "print(f\"Training size: {len(train_dataset)}, Evaluation size: {len(eval_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load Tokenizer and Model\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 348775/348775 [03:09<00:00, 1837.04 examples/s]\n",
      "Map: 100%|██████████| 38753/38753 [00:20<00:00, 1930.00 examples/s]\n",
      "Map: 100%|██████████| 348775/348775 [00:18<00:00, 19063.79 examples/s]\n",
      "Map: 100%|██████████| 38753/38753 [00:01<00:00, 20609.38 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize Dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_eval = eval_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "tokenized_train = tokenized_train.map(lambda examples: {'labels': torch.tensor(examples['polarity'], dtype=torch.long)})\n",
    "tokenized_eval = tokenized_eval.map(lambda examples: {'labels': torch.tensor(examples['polarity'], dtype=torch.long)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'polarity', 'source', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 348775\n",
       "})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'polarity', 'source', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 38753\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: [101, 1996, 5790, 1045, 2435, 2323, 2941, 2022, 1037, 5717, 2349, 2000, 3532, 8013, 2326, 1012, 2044, 8110, 2041, 1996, 2433, 2006, 1996, 4037, 2445, 2006, 2026, 3025, 3319, 2035, 1045, 2363, 2001, 1037, 7514, 2011, 1000, 6207, 1000, 1999, 8013, 2326, 4129, 2033, 2000, 2655, 1012, 1045, 1005, 2310, 2525, 5287, 2055, 1996, 3573, 1012, 2023, 3006, 2006, 10688, 27136, 2015, 1010, 6719, 1998, 29407, 2135, 1012, 8013, 2326, 2005, 2023, 2194, 2003, 2512, 4839, 4630, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Decoded Text: the rating i gave should actually be a zero due to poor customer service. after filling out the form on the website given on my previous review all i received was a reply by \" apple \" in customer service telling me to call. i've already spoken about the store. this market on speedway stinks, literally and figuratively. customer service for this company is non existant.\n"
     ]
    }
   ],
   "source": [
    "# Inspect the First Row of Tokenized Train Dataset\n",
    "row = tokenized_train[0]\n",
    "\n",
    "# Print `input_ids`\n",
    "print(\"Input IDs:\", row['input_ids'])\n",
    "\n",
    "# Decode Back to Text (Optional)\n",
    "decoded_text = tokenizer.decode(row['input_ids'], skip_special_tokens=True)\n",
    "print(\"Decoded Text:\", decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epochs = 3\n",
    "total_steps = (len(tokenized_train) // batch_size) * epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./basemodel_results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=epochs,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=int(0.1 * total_steps),\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=10,\n",
    "    logging_dir=\"./logs\",\n",
    "    report_to=\"none\",\n",
    "    logging_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_eval,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.evaluate()\n",
    "\n",
    "model.save_pretrained('./basemodel_sentiment_model')\n",
    "tokenizer.save_pretrained('./basemodel_sentiment_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
