{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slang dataset\n",
    "\n",
    "https://huggingface.co/datasets/MLBtrio/genz-slang-dataset/viewer/default/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "slang_dataset = load_dataset(\"MLBtrio/genz-slang-dataset\")\n",
    "slang_words = [entry['Slang'] for entry in slang_dataset['train'] if ' ' not in entry['Slang'] and entry['Slang'].isalpha()]\n",
    "slang_words_set = set(word.lower() for word in slang_words)\n",
    "slang_words_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- awww, that's a bummer.  you shoulda got davi...</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his facebook by ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i dived many times for the ball. managed to sa...</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no, it's not behaving at all. i'm mad. why am ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196816</th>\n",
       "      <td>best viet hoagies you'll find in the area, or ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196817</th>\n",
       "      <td>if you need medical testing of any kind, i wou...</td>\n",
       "      <td>1</td>\n",
       "      <td>Yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196818</th>\n",
       "      <td>this place is a dream. honestly my favorite in...</td>\n",
       "      <td>1</td>\n",
       "      <td>Yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196819</th>\n",
       "      <td>great place to have your dog groom. my one dog...</td>\n",
       "      <td>1</td>\n",
       "      <td>Yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196820</th>\n",
       "      <td>this salon is great! the pedicure was great, g...</td>\n",
       "      <td>1</td>\n",
       "      <td>Yelp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2196821 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  polarity   source\n",
       "0        - awww, that's a bummer.  you shoulda got davi...         0  Twitter\n",
       "1        is upset that he can't update his facebook by ...         0  Twitter\n",
       "2        i dived many times for the ball. managed to sa...         0  Twitter\n",
       "3           my whole body feels itchy and like its on fire         0  Twitter\n",
       "4        no, it's not behaving at all. i'm mad. why am ...         0  Twitter\n",
       "...                                                    ...       ...      ...\n",
       "2196816  best viet hoagies you'll find in the area, or ...         1     Yelp\n",
       "2196817  if you need medical testing of any kind, i wou...         1     Yelp\n",
       "2196818  this place is a dream. honestly my favorite in...         1     Yelp\n",
       "2196819  great place to have your dog groom. my one dog...         1     Yelp\n",
       "2196820  this salon is great! the pedicure was great, g...         1     Yelp\n",
       "\n",
       "[2196821 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Datasets/Cleaned with tokens/combined_dataset.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slang_tokenizer(text):\n",
    "    tokens = word_tokenize(text.lower(), language='english', preserve_line=True)\n",
    "    return [word for word in tokens if word.isalpha() and word in slang_words_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=slang_tokenizer, lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = vectorizer.fit_transform(data['text'])\n",
    "\n",
    "# Create a DataFrame to display results\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "tfidf_df.index = data.index\n",
    "\n",
    "# Aggregate TF-IDF scores for each slang term\n",
    "slang_scores = tfidf_df.sum(axis=0).sort_values(ascending=False)\n",
    "slang_scores.to_csv('slang_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Test the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "words = [\"u\", \"im\", \"wat\", 'lmao', 'lol', 'brb', 'omg', 'wtf', 'smh', 'idk', 'tbh', 'sry']\n",
    "for word in words:\n",
    "    token_id = tokenizer.convert_tokens_to_ids(word)\n",
    "    if token_id == 100:  # ID 100 corresponds to the [UNK] token\n",
    "        print(f\"'{word}' is NOT in the BERT vocabulary (mapped to [UNK]).\")\n",
    "    else:\n",
    "        print(f\"'{word}' is in the BERT vocabulary with ID {token_id}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for example usage of the slang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Slang</th>\n",
       "      <th>TF-IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>was</td>\n",
       "      <td>217339.246501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>so</td>\n",
       "      <td>165827.902975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>at</td>\n",
       "      <td>165670.348117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>are</td>\n",
       "      <td>156590.391256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>we</td>\n",
       "      <td>143283.229747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>know</td>\n",
       "      <td>59756.043378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lol</td>\n",
       "      <td>41691.810161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>im</td>\n",
       "      <td>41467.735488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>oh</td>\n",
       "      <td>35708.223269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>u</td>\n",
       "      <td>34531.078095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bio</td>\n",
       "      <td>13142.782625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>x</td>\n",
       "      <td>12448.290880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>girl</td>\n",
       "      <td>12011.468697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>wow</td>\n",
       "      <td>11133.654649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>omg</td>\n",
       "      <td>10127.133476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ur</td>\n",
       "      <td>9137.940759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mom</td>\n",
       "      <td>9090.358271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ta</td>\n",
       "      <td>8994.719377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ya</td>\n",
       "      <td>8771.204033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>pm</td>\n",
       "      <td>8531.381074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>woke</td>\n",
       "      <td>7320.345181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>hand</td>\n",
       "      <td>6708.190939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>add</td>\n",
       "      <td>6649.110729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>extra</td>\n",
       "      <td>6413.581693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>w</td>\n",
       "      <td>6169.194474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>b</td>\n",
       "      <td>6168.042916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>dad</td>\n",
       "      <td>5928.215231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sat</td>\n",
       "      <td>5749.542088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>air</td>\n",
       "      <td>5736.559602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>sit</td>\n",
       "      <td>5565.834434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Slang         TF-IDF\n",
       "0     was  217339.246501\n",
       "1      so  165827.902975\n",
       "2      at  165670.348117\n",
       "3     are  156590.391256\n",
       "4      we  143283.229747\n",
       "5    know   59756.043378\n",
       "6     lol   41691.810161\n",
       "7      im   41467.735488\n",
       "8      oh   35708.223269\n",
       "9       u   34531.078095\n",
       "10    bio   13142.782625\n",
       "11      x   12448.290880\n",
       "12   girl   12011.468697\n",
       "13    wow   11133.654649\n",
       "14    omg   10127.133476\n",
       "15     ur    9137.940759\n",
       "16    mom    9090.358271\n",
       "17     ta    8994.719377\n",
       "18     ya    8771.204033\n",
       "19     pm    8531.381074\n",
       "20   woke    7320.345181\n",
       "21   hand    6708.190939\n",
       "22    add    6649.110729\n",
       "23  extra    6413.581693\n",
       "24      w    6169.194474\n",
       "25      b    6168.042916\n",
       "26    dad    5928.215231\n",
       "27    sat    5749.542088\n",
       "28    air    5736.559602\n",
       "29    sit    5565.834434"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_csv = pd.read_csv('slang_scores.csv', header=0, names=['Slang', 'TF-IDF'])\n",
    "tfidf_csv_selected = tfidf_csv[tfidf_csv['TF-IDF'] > 50]\n",
    "tfidf_csv_selected_first_20 = tfidf_csv_selected.head(30)\n",
    "tfidf_csv_selected_first_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sentences_with_slang(df, slang, max_samples=3):\n",
    "    matching_sentences = []\n",
    "    for sentence in df[\"text\"]:\n",
    "        tokens = word_tokenize(sentence.lower())\n",
    "        if slang in tokens:\n",
    "            matching_sentences.append(sentence)\n",
    "        if len(matching_sentences) >= max_samples:\n",
    "            break\n",
    "    return matching_sentences\n",
    "\n",
    "results = {}\n",
    "\n",
    "column_list = tfidf_csv_selected_first_20['Slang'].tolist()\n",
    "\n",
    "for slang in column_list:\n",
    "    sentences = find_sentences_with_slang(data, slang, max_samples=3)\n",
    "    if sentences:\n",
    "        results[slang] = sentences\n",
    "\n",
    "if results:\n",
    "    results_df = pd.DataFrame([\n",
    "        {\"Slang\": slang, \"Sentence\": sentence}\n",
    "        for slang, sentences in results.items()\n",
    "        for sentence in sentences\n",
    "    ])\n",
    "else:\n",
    "    print(\"No slang terms found in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Slang</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>was</td>\n",
       "      <td>i couldn't bear to watch it.  and i thought the ua loss was embarrassing . . . . .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>was</td>\n",
       "      <td>i wish i got to watch it with you!! i miss you and   how was the premiere?!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>was</td>\n",
       "      <td>i was out most of the day so didn't get much done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>so</td>\n",
       "      <td>i was out most of the day so didn't get much done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>so</td>\n",
       "      <td>ooooh.... lol  that leslie.... and ok i won't do it again so leslie won't  get mad again</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>so</td>\n",
       "      <td>oh! i'm so sorry  i didn't think about that before retweeting.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>at</td>\n",
       "      <td>no, it's not behaving at all. i'm mad. why am i here? because i can't see you all over there.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>at</td>\n",
       "      <td>one of my friend called me, and asked to meet with her at mid valley today...but i've no time sigh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>at</td>\n",
       "      <td>blagh class at  tomorrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>are</td>\n",
       "      <td>just checked my user timeline on my blackberry, it looks like the twanking is still happening  are ppl still having probs w bgs and uids?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>are</td>\n",
       "      <td>broadband plan 'a massive broken promise'  via www.diigo.comtautao still waiting for broadband we are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>are</td>\n",
       "      <td>our duck and chicken are taking wayyy too long to hatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>we</td>\n",
       "      <td>broadband plan 'a massive broken promise'  via www.diigo.comtautao still waiting for broadband we are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>we</td>\n",
       "      <td>i should have paid more attention when we covered photoshop in my webpage design class in undergrad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>we</td>\n",
       "      <td>but this is canada  canada is weird. we're supposed to get snow through wednesday. ugh.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>know</td>\n",
       "      <td>i don't either. its depressing. i don't think i even want to know about the kids in suitcases.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>know</td>\n",
       "      <td>sad, sad, sad. i don't know why but i hate this feeling  i wanna sleep and i still can't!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>know</td>\n",
       "      <td>wednesday my b-day! don't know what  do!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>lol</td>\n",
       "      <td>hey  long time no see! yes.. rains a bit ,only a bit  lol , i'm fine thanks , how's you ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>lol</td>\n",
       "      <td>ooooh.... lol  that leslie.... and ok i won't do it again so leslie won't  get mad again</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>lol</td>\n",
       "      <td>lol.. wish they understood daylight savings has ended though and breakfast is an hour later  they keep waking the kids up too</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>im</td>\n",
       "      <td>im sad now  miss.lilly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>im</td>\n",
       "      <td>awww i soo wish i was there to see you finally comfortable! im sad that i missed it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>im</td>\n",
       "      <td>aaw i miss ya all too.. im leaving to bh tomorrow quot;morningquot; i think.. aww i wanna go to the beach w u girls!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>oh</td>\n",
       "      <td>oh dear. were you drinking out of the forgotten table drinks?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>oh</td>\n",
       "      <td>oh man...was ironing 's fave top to wear to a meeting. burnt it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>oh</td>\n",
       "      <td>oh! i'm so sorry  i didn't think about that before retweeting.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>u</td>\n",
       "      <td>where did u move to?  i thought u were already in sd. ?? hmmm. random u found me. glad to hear yer doing well.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>u</td>\n",
       "      <td>wonders why someone that u like so much can make you so unhappy in a split seccond . depressed .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>u</td>\n",
       "      <td>hmm  , do u really enjoy being with him ? if the problems are too constants u should think things more , find someone ulike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>bio</td>\n",
       "      <td>lol.  u read my bio but spelt my name wrong           darylo ... ahem ;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>bio</td>\n",
       "      <td>someone save me from bio lecture... its too early for this! and my knee is black and blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>bio</td>\n",
       "      <td>bio test was easy, which means i probably failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>x</td>\n",
       "      <td>do u write back on twitter? i miss ya garee...  x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>x</td>\n",
       "      <td>morning everyone!! still feeling poorly!   hope u all have a good day! x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>x</td>\n",
       "      <td>sorry to hear that.  anything specific? x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>girl</td>\n",
       "      <td>falling asleep. just heard about that tracy girl's body being found. how sad  my heart breaks for that family.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>girl</td>\n",
       "      <td>body of missing northern calif. girl found: police have found the remains of a missing northern california girl ..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>girl</td>\n",
       "      <td>i just saw that they found that tracy girl in a piece of luggage... how fucking terrible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>wow</td>\n",
       "      <td>wow, tons of replies from you, may have to unfollow so i can see my friends' tweets, you're scrolling the feed a lot.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>wow</td>\n",
       "      <td>wow. the most depressing thing in the world is losing a video that you've created in a matter of seconds.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>wow</td>\n",
       "      <td>wow that last tweet made me seem like a giant sexist...sorry about that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>omg</td>\n",
       "      <td>omg. my mouth is in so much pain  i just wanna sleep untill its time to take my braces off.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>omg</td>\n",
       "      <td>lol they are some emotional ass men!! omg all this late night eating.. both of us are broke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>omg</td>\n",
       "      <td>omg i've an economics test. and i dont know all the things i have to know and omg im gonna fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>ur</td>\n",
       "      <td>just got ur newsletter, those fares really are unbelievable, shame i already booked and paid for mine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>ur</td>\n",
       "      <td>i think ur right!! hahaha!! . hrs now!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>ur</td>\n",
       "      <td>i think maybe you should get a couple more hours of sleep, hon. how productive can you be right now if ur dog tired? i worry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>mom</td>\n",
       "      <td>my mom might have breast cancer won't find out anything for. like a week i'm so worried!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>mom</td>\n",
       "      <td>watching fallon with mom and working on a project...school is hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>mom</td>\n",
       "      <td>my mom has it. i wish you the best of luck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ta</td>\n",
       "      <td>i have a sad feeling that dallas is not going to show up  i gotta say though, you'd think more shows would use music from the game. mmm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ta</td>\n",
       "      <td>gotta do my cooking assignment  its too hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>ta</td>\n",
       "      <td>gotta repeat  whole art folio cuz old one with a whole terms work got wet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>ya</td>\n",
       "      <td>ill tell ya the story later  not a good day and ill be workin for like three more hours...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>ya</td>\n",
       "      <td>hey missed ya at the meeting  sup mama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>ya</td>\n",
       "      <td>aaw i miss ya all too.. im leaving to bh tomorrow quot;morningquot; i think.. aww i wanna go to the beach w u girls!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>pm</td>\n",
       "      <td>geez what a busy afternoon. meetings, emails, meetings and email and more meetings. pm and the day is still going! ah its dark and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>pm</td>\n",
       "      <td>what? apparently it's  degress at pm in washington state. i miss winter already</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>pm</td>\n",
       "      <td>quot;sfmta budget proposal hearing: tomorrow, april  at : pm city hall, room . sadly, i cannot attend.quot; me neither.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>woke</td>\n",
       "      <td>just woke up an already have written some e-mail... i've to go early at university today as i have to teach at : am!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>woke</td>\n",
       "      <td>woke up and was having an accident - quot;it's pushing, it's pushing!quot; he was crying because he couldn't stop from wetting his pants.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>woke</td>\n",
       "      <td>just woke up from the most vivid, sketchy, not-cool dreams of my life. time to stare at the wall with the lights on.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>hand</td>\n",
       "      <td>played another hand very bad and lost half my stack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>hand</td>\n",
       "      <td>am trying to fit all my stuff in a tiny bag so i can take it on as hand luggage. dont think its gonna work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>hand</td>\n",
       "      <td>riry is being a pain and nomming on my hand. should not have sprayed her with that cat nip mist as a joke.  now she is craaaazy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>add</td>\n",
       "      <td>can do everything except add a twitter field in the comment..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>add</td>\n",
       "      <td>they end up back as read only ... and still the error persists. i cant add anything to the library now   so cant update my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>add</td>\n",
       "      <td>is it possible to add another stream option that uses the regular  port? i can't stream noagenda because of fwproxy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>extra</td>\n",
       "      <td>so glad i made it through work - with an extra hour too and my paycheck.  still waiting on the one i lost though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>extra</td>\n",
       "      <td>argh.  driving into london today.  made a wrong turn at kings-x - stuck in an extra  minutes of logjam traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>extra</td>\n",
       "      <td>via : argh.  driving into london today.  made a wrong turn at kings-x - stuck in an extra  minutes of logjam traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>w</td>\n",
       "      <td>just checked my user timeline on my blackberry, it looks like the twanking is still happening  are ppl still having probs w bgs and uids?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>w</td>\n",
       "      <td>aaw i miss ya all too.. im leaving to bh tomorrow quot;morningquot; i think.. aww i wanna go to the beach w u girls!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>w</td>\n",
       "      <td>w every person there. i didn't get a pic  my phone died but he signed my shirt so amazing words cannot describe should've skipped mel lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>b</td>\n",
       "      <td>i want to go to promote gear and groove but unfornately no ride there  i may b going to the one in anaheim in may though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>b</td>\n",
       "      <td>so rylee,grace...wana go steve's party or not?? sadly since its easter i wnt b able  do much  but ohh well.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>b</td>\n",
       "      <td>- i hate  b allergic  i want a puppy soo bad that i've already thought some cool names</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>dad</td>\n",
       "      <td>bad news was dad has cancer and is dying   good news new business started and  i am now a life coach practising holistic weight management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>dad</td>\n",
       "      <td>my mom amp; dad both get up around ...too early for me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>dad</td>\n",
       "      <td>guess what? my dad is pregnant!!! lol nah, the doctor does have to give him an epidural for his chronic back pain, though.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>sat</td>\n",
       "      <td>rachel! hang outage is neccessary - i was gonna be home this wekend but dumb folk make me work   so im free f and sat until ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>sat</td>\n",
       "      <td>i am home missing my baby  busy week ahead fri is a chill day with my guy and kids, egg hunt sat, spiral and dmb sat night and easter!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>sat</td>\n",
       "      <td>ugh of course not  just thursday and friday..sat i have both kids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>air</td>\n",
       "      <td>i'm laying in bed facing the wall and trying to relax but i'm hearing so many things plus the air conditioning sound is so louad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>air</td>\n",
       "      <td>made it into dc on saturday afternoon after  hours in air and am now in south fl...jetlag sucks!!  haven't had a full sleep since thurs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>air</td>\n",
       "      <td>am sorry to say but it is still in the air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>sit</td>\n",
       "      <td>no sun here  and i was hoping to sit out on the balcony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>sit</td>\n",
       "      <td>haha i got to be up at   and sit through a  hr mass. umm like  ish ..is that alright? is that too late?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>sit</td>\n",
       "      <td>might go sit on the swing and do some revision later. i want to go on holiday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Slang  \\\n",
       "0     was   \n",
       "1     was   \n",
       "2     was   \n",
       "3      so   \n",
       "4      so   \n",
       "5      so   \n",
       "6      at   \n",
       "7      at   \n",
       "8      at   \n",
       "9     are   \n",
       "10    are   \n",
       "11    are   \n",
       "12     we   \n",
       "13     we   \n",
       "14     we   \n",
       "15   know   \n",
       "16   know   \n",
       "17   know   \n",
       "18    lol   \n",
       "19    lol   \n",
       "20    lol   \n",
       "21     im   \n",
       "22     im   \n",
       "23     im   \n",
       "24     oh   \n",
       "25     oh   \n",
       "26     oh   \n",
       "27      u   \n",
       "28      u   \n",
       "29      u   \n",
       "30    bio   \n",
       "31    bio   \n",
       "32    bio   \n",
       "33      x   \n",
       "34      x   \n",
       "35      x   \n",
       "36   girl   \n",
       "37   girl   \n",
       "38   girl   \n",
       "39    wow   \n",
       "40    wow   \n",
       "41    wow   \n",
       "42    omg   \n",
       "43    omg   \n",
       "44    omg   \n",
       "45     ur   \n",
       "46     ur   \n",
       "47     ur   \n",
       "48    mom   \n",
       "49    mom   \n",
       "50    mom   \n",
       "51     ta   \n",
       "52     ta   \n",
       "53     ta   \n",
       "54     ya   \n",
       "55     ya   \n",
       "56     ya   \n",
       "57     pm   \n",
       "58     pm   \n",
       "59     pm   \n",
       "60   woke   \n",
       "61   woke   \n",
       "62   woke   \n",
       "63   hand   \n",
       "64   hand   \n",
       "65   hand   \n",
       "66    add   \n",
       "67    add   \n",
       "68    add   \n",
       "69  extra   \n",
       "70  extra   \n",
       "71  extra   \n",
       "72      w   \n",
       "73      w   \n",
       "74      w   \n",
       "75      b   \n",
       "76      b   \n",
       "77      b   \n",
       "78    dad   \n",
       "79    dad   \n",
       "80    dad   \n",
       "81    sat   \n",
       "82    sat   \n",
       "83    sat   \n",
       "84    air   \n",
       "85    air   \n",
       "86    air   \n",
       "87    sit   \n",
       "88    sit   \n",
       "89    sit   \n",
       "\n",
       "                                                                                                                                      Sentence  \n",
       "0                                                           i couldn't bear to watch it.  and i thought the ua loss was embarrassing . . . . .  \n",
       "1                                                                  i wish i got to watch it with you!! i miss you and   how was the premiere?!  \n",
       "2                                                                                            i was out most of the day so didn't get much done  \n",
       "3                                                                                            i was out most of the day so didn't get much done  \n",
       "4                                                     ooooh.... lol  that leslie.... and ok i won't do it again so leslie won't  get mad again  \n",
       "5                                                                               oh! i'm so sorry  i didn't think about that before retweeting.  \n",
       "6                                                no, it's not behaving at all. i'm mad. why am i here? because i can't see you all over there.  \n",
       "7                                           one of my friend called me, and asked to meet with her at mid valley today...but i've no time sigh  \n",
       "8                                                                                                                     blagh class at  tomorrow  \n",
       "9    just checked my user timeline on my blackberry, it looks like the twanking is still happening  are ppl still having probs w bgs and uids?  \n",
       "10                                       broadband plan 'a massive broken promise'  via www.diigo.comtautao still waiting for broadband we are  \n",
       "11                                                                                     our duck and chicken are taking wayyy too long to hatch  \n",
       "12                                       broadband plan 'a massive broken promise'  via www.diigo.comtautao still waiting for broadband we are  \n",
       "13                                         i should have paid more attention when we covered photoshop in my webpage design class in undergrad  \n",
       "14                                                     but this is canada  canada is weird. we're supposed to get snow through wednesday. ugh.  \n",
       "15                                              i don't either. its depressing. i don't think i even want to know about the kids in suitcases.  \n",
       "16                                                   sad, sad, sad. i don't know why but i hate this feeling  i wanna sleep and i still can't!  \n",
       "17                                                                                                   wednesday my b-day! don't know what  do!!  \n",
       "18                                                   hey  long time no see! yes.. rains a bit ,only a bit  lol , i'm fine thanks , how's you ?  \n",
       "19                                                    ooooh.... lol  that leslie.... and ok i won't do it again so leslie won't  get mad again  \n",
       "20               lol.. wish they understood daylight savings has ended though and breakfast is an hour later  they keep waking the kids up too  \n",
       "21                                                                                                                      im sad now  miss.lilly  \n",
       "22                                                         awww i soo wish i was there to see you finally comfortable! im sad that i missed it  \n",
       "23                       aaw i miss ya all too.. im leaving to bh tomorrow quot;morningquot; i think.. aww i wanna go to the beach w u girls!!  \n",
       "24                                                                               oh dear. were you drinking out of the forgotten table drinks?  \n",
       "25                                                                             oh man...was ironing 's fave top to wear to a meeting. burnt it  \n",
       "26                                                                              oh! i'm so sorry  i didn't think about that before retweeting.  \n",
       "27                              where did u move to?  i thought u were already in sd. ?? hmmm. random u found me. glad to hear yer doing well.  \n",
       "28                                            wonders why someone that u like so much can make you so unhappy in a split seccond . depressed .  \n",
       "29                 hmm  , do u really enjoy being with him ? if the problems are too constants u should think things more , find someone ulike  \n",
       "30                                                                     lol.  u read my bio but spelt my name wrong           darylo ... ahem ;  \n",
       "31                                                   someone save me from bio lecture... its too early for this! and my knee is black and blue  \n",
       "32                                                                                            bio test was easy, which means i probably failed  \n",
       "33                                                                                           do u write back on twitter? i miss ya garee...  x  \n",
       "34                                                                    morning everyone!! still feeling poorly!   hope u all have a good day! x  \n",
       "35                                                                                                   sorry to hear that.  anything specific? x  \n",
       "36                              falling asleep. just heard about that tracy girl's body being found. how sad  my heart breaks for that family.  \n",
       "37                          body of missing northern calif. girl found: police have found the remains of a missing northern california girl ..  \n",
       "38                                                    i just saw that they found that tracy girl in a piece of luggage... how fucking terrible  \n",
       "39                       wow, tons of replies from you, may have to unfollow so i can see my friends' tweets, you're scrolling the feed a lot.  \n",
       "40                                   wow. the most depressing thing in the world is losing a video that you've created in a matter of seconds.  \n",
       "41                                                                     wow that last tweet made me seem like a giant sexist...sorry about that  \n",
       "42                                                 omg. my mouth is in so much pain  i just wanna sleep untill its time to take my braces off.  \n",
       "43                                                 lol they are some emotional ass men!! omg all this late night eating.. both of us are broke  \n",
       "44                                             omg i've an economics test. and i dont know all the things i have to know and omg im gonna fail  \n",
       "45                                       just got ur newsletter, those fares really are unbelievable, shame i already booked and paid for mine  \n",
       "46                                                                                                     i think ur right!! hahaha!! . hrs now!!  \n",
       "47                i think maybe you should get a couple more hours of sleep, hon. how productive can you be right now if ur dog tired? i worry  \n",
       "48                                                    my mom might have breast cancer won't find out anything for. like a week i'm so worried!  \n",
       "49                                                                          watching fallon with mom and working on a project...school is hard  \n",
       "50                                                                                                  my mom has it. i wish you the best of luck  \n",
       "51     i have a sad feeling that dallas is not going to show up  i gotta say though, you'd think more shows would use music from the game. mmm  \n",
       "52                                                                                                gotta do my cooking assignment  its too hard  \n",
       "53                                                                   gotta repeat  whole art folio cuz old one with a whole terms work got wet  \n",
       "54                                                  ill tell ya the story later  not a good day and ill be workin for like three more hours...  \n",
       "55                                                                                                      hey missed ya at the meeting  sup mama  \n",
       "56                       aaw i miss ya all too.. im leaving to bh tomorrow quot;morningquot; i think.. aww i wanna go to the beach w u girls!!  \n",
       "57          geez what a busy afternoon. meetings, emails, meetings and email and more meetings. pm and the day is still going! ah its dark and  \n",
       "58                                                             what? apparently it's  degress at pm in washington state. i miss winter already  \n",
       "59                     quot;sfmta budget proposal hearing: tomorrow, april  at : pm city hall, room . sadly, i cannot attend.quot; me neither.  \n",
       "60                        just woke up an already have written some e-mail... i've to go early at university today as i have to teach at : am!  \n",
       "61   woke up and was having an accident - quot;it's pushing, it's pushing!quot; he was crying because he couldn't stop from wetting his pants.  \n",
       "62                        just woke up from the most vivid, sketchy, not-cool dreams of my life. time to stare at the wall with the lights on.  \n",
       "63                                                                                         played another hand very bad and lost half my stack  \n",
       "64                                  am trying to fit all my stuff in a tiny bag so i can take it on as hand luggage. dont think its gonna work  \n",
       "65             riry is being a pain and nomming on my hand. should not have sprayed her with that cat nip mist as a joke.  now she is craaaazy  \n",
       "66                                                                               can do everything except add a twitter field in the comment..  \n",
       "67              they end up back as read only ... and still the error persists. i cant add anything to the library now   so cant update my ...  \n",
       "68                         is it possible to add another stream option that uses the regular  port? i can't stream noagenda because of fwproxy  \n",
       "69                            so glad i made it through work - with an extra hour too and my paycheck.  still waiting on the one i lost though  \n",
       "70                              argh.  driving into london today.  made a wrong turn at kings-x - stuck in an extra  minutes of logjam traffic  \n",
       "71                        via : argh.  driving into london today.  made a wrong turn at kings-x - stuck in an extra  minutes of logjam traffic  \n",
       "72   just checked my user timeline on my blackberry, it looks like the twanking is still happening  are ppl still having probs w bgs and uids?  \n",
       "73                       aaw i miss ya all too.. im leaving to bh tomorrow quot;morningquot; i think.. aww i wanna go to the beach w u girls!!  \n",
       "74   w every person there. i didn't get a pic  my phone died but he signed my shirt so amazing words cannot describe should've skipped mel lol  \n",
       "75                    i want to go to promote gear and groove but unfornately no ride there  i may b going to the one in anaheim in may though  \n",
       "76                             so rylee,grace...wana go steve's party or not?? sadly since its easter i wnt b able  do much  but ohh well.....  \n",
       "77                                                      - i hate  b allergic  i want a puppy soo bad that i've already thought some cool names  \n",
       "78  bad news was dad has cancer and is dying   good news new business started and  i am now a life coach practising holistic weight management  \n",
       "79                                                                                      my mom amp; dad both get up around ...too early for me  \n",
       "80                  guess what? my dad is pregnant!!! lol nah, the doctor does have to give him an epidural for his chronic back pain, though.  \n",
       "81             rachel! hang outage is neccessary - i was gonna be home this wekend but dumb folk make me work   so im free f and sat until ...  \n",
       "82      i am home missing my baby  busy week ahead fri is a chill day with my guy and kids, egg hunt sat, spiral and dmb sat night and easter!  \n",
       "83                                                                           ugh of course not  just thursday and friday..sat i have both kids  \n",
       "84            i'm laying in bed facing the wall and trying to relax but i'm hearing so many things plus the air conditioning sound is so louad  \n",
       "85     made it into dc on saturday afternoon after  hours in air and am now in south fl...jetlag sucks!!  haven't had a full sleep since thurs  \n",
       "86                                                                                                  am sorry to say but it is still in the air  \n",
       "87                                                                                     no sun here  and i was hoping to sit out on the balcony  \n",
       "88                                     haha i got to be up at   and sit through a  hr mass. umm like  ish ..is that alright? is that too late?  \n",
       "89                                                               might go sit on the swing and do some revision later. i want to go on holiday  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserting slang into BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1f4322c2d90>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "TORCH_SEED = 42\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "torch.manual_seed(TORCH_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1193514 word vectors from GloVe.\n"
     ]
    }
   ],
   "source": [
    "def load_glove_embeddings(file_path):\n",
    "    embeddings_index = {}\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = vector\n",
    "    \n",
    "    print(f\"Loaded {len(embeddings_index)} word vectors from GloVe.\")\n",
    "    return embeddings_index\n",
    "\n",
    "file_path = 'Embeddings/glove.twitter.27B/glove.twitter.27B.200d.txt'\n",
    "glove_embeddings = load_glove_embeddings(file_path)\n",
    "GLOVE_EMBEDDING_SIZE = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "slang_words = [\"lol\", \"lmao\", \"omg\", \"wtf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized 'lol' with projected GloVe weights.\n",
      "Initialized 'lmao' with projected GloVe weights.\n",
      "Initialized 'omg' with projected GloVe weights.\n",
      "Initialized 'wtf' with projected GloVe weights.\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.bert.embeddings.word_embeddings\n",
    "\n",
    "projection_layer = torch.nn.Linear(GLOVE_EMBEDDING_SIZE, model.config.hidden_size)\n",
    "\n",
    "new_tokens = [token for token in slang_words if token not in tokenizer.get_vocab()]\n",
    "tokenizer.add_tokens(new_tokens)\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "embedding_layer = model.bert.embeddings.word_embeddings\n",
    "\n",
    "for slang in new_tokens:\n",
    "    token_index = tokenizer.convert_tokens_to_ids(slang)\n",
    "    \n",
    "    if slang in glove_embeddings:\n",
    "        glove_vector = torch.tensor(glove_embeddings[slang], dtype=torch.float32)\n",
    "        projected_vector = projection_layer(glove_vector.unsqueeze(0)).squeeze(0)\n",
    "        embedding_layer.weight.data[token_index] = projected_vector\n",
    "        print(f\"Initialized '{slang}' with projected GloVe weights.\")\n",
    "    else:\n",
    "        embedding_layer.weight.data[token_index] = torch.randn(model.config.hidden_size)\n",
    "        print(f\"Initialized '{slang}' with random weights.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'lol' successfully added to the tokenizer with index 30522.\n",
      "'lmao' successfully added to the tokenizer with index 30523.\n",
      "'omg' successfully added to the tokenizer with index 30524.\n",
      "'wtf' successfully added to the tokenizer with index 30525.\n"
     ]
    }
   ],
   "source": [
    "for slang in slang_words:\n",
    "    token_index = tokenizer.convert_tokens_to_ids(slang)\n",
    "    if token_index != tokenizer.unk_token_id:\n",
    "        print(f\"'{slang}' successfully added to the tokenizer with index {token_index}.\")\n",
    "    else:\n",
    "        print(f\"'{slang}' was not added to the tokenizer.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for 'lol': tensor([-0.0323, -0.4869, -0.0764,  0.5014, -0.4434])\n",
      "Embedding for 'lmao': tensor([-0.1084, -0.4460, -0.1522,  0.3065, -0.4368])\n",
      "Embedding for 'omg': tensor([ 0.0654, -0.4869,  0.0401,  0.2163, -0.0247])\n",
      "Embedding for 'wtf': tensor([ 0.0321, -0.6249, -0.0311,  0.2451, -0.1961])\n"
     ]
    }
   ],
   "source": [
    "for slang in slang_words:\n",
    "    token_index = tokenizer.convert_tokens_to_ids(slang)\n",
    "    if token_index != tokenizer.unk_token_id:\n",
    "        embedding_vector = embedding_layer.weight.data[token_index]\n",
    "        print(f\"Embedding for '{slang}': {embedding_vector[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'lol': Initialized with GloVe? Yes\n",
      "'lmao': Initialized with GloVe? Yes\n",
      "'omg': Initialized with GloVe? Yes\n",
      "'wtf': Initialized with GloVe? Yes\n"
     ]
    }
   ],
   "source": [
    "for slang in slang_words:\n",
    "    token_index = tokenizer.convert_tokens_to_ids(slang)\n",
    "    if slang in glove_embeddings and token_index != tokenizer.unk_token_id:\n",
    "        glove_vector = torch.tensor(glove_embeddings[slang], dtype=torch.float32)\n",
    "        projected_vector = projection_layer(glove_vector.unsqueeze(0)).squeeze(0)\n",
    "        bert_embedding = embedding_layer.weight.data[token_index]\n",
    "        is_close = torch.allclose(bert_embedding, projected_vector, atol=1e-3)\n",
    "        print(f\"'{slang}': Initialized with GloVe? {'Yes' if is_close else 'No'}\")\n",
    "\n",
    "for slang in slang_words:\n",
    "    token_index = tokenizer.convert_tokens_to_ids(slang)\n",
    "    if slang not in glove_embeddings and token_index != tokenizer.unk_token_id:\n",
    "        embedding_vector = embedding_layer.weight.data[token_index]\n",
    "        print(f\"'{slang}' was randomly initialized with values: {embedding_vector[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserting emoji in BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import keyedvectors\n",
    "\n",
    "e2v = keyedvectors.load_word2vec_format('Embeddings/emoji2vec.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of e2v embedding: 300\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dimension of e2v embedding:\", e2v[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "E2V_EMBEDDING_SIZE = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_list = [\"😀\", \"😂\", \"❤️\", \"🔥\", \"👍\", \"😭\", \"🙏\", \"🥺\", \"😍\", \"😅\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized '😀' with projected e2v weights.\n",
      "Initialized '😂' with projected e2v weights.\n",
      "Initialized '❤️' with projected e2v weights.\n",
      "Initialized '🔥' with projected e2v weights.\n",
      "Initialized '👍' with projected e2v weights.\n",
      "Initialized '😭' with projected e2v weights.\n",
      "Initialized '🙏' with projected e2v weights.\n",
      "Initialized '🥺' with random weights.\n",
      "Initialized '😍' with projected e2v weights.\n",
      "Initialized '😅' with projected e2v weights.\n"
     ]
    }
   ],
   "source": [
    "new_emoji_tokens = [emoji for emoji in emoji_list if emoji not in tokenizer.get_vocab()]\n",
    "tokenizer.add_tokens(new_emoji_tokens)\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "embedding_layer = model.bert.embeddings.word_embeddings\n",
    "\n",
    "emoji_projection_layer = torch.nn.Linear(E2V_EMBEDDING_SIZE, model.config.hidden_size)\n",
    "\n",
    "for emoji in new_emoji_tokens:\n",
    "    token_index = tokenizer.convert_tokens_to_ids(emoji)\n",
    "    \n",
    "    if emoji in e2v:\n",
    "        e2v_vector = torch.tensor(e2v[emoji], dtype=torch.float32)\n",
    "        projected_vector = emoji_projection_layer(e2v_vector.unsqueeze(0)).squeeze(0)\n",
    "        embedding_layer.weight.data[token_index] = projected_vector\n",
    "        print(f\"Initialized '{emoji}' with projected e2v weights.\")\n",
    "    else:\n",
    "        embedding_layer.weight.data[token_index] = torch.randn(model.config.hidden_size)\n",
    "        print(f\"Initialized '{emoji}' with random weights.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'😀' initialized with Emoji2Vec weights.\n",
      "'😂' initialized with Emoji2Vec weights.\n",
      "'❤️' initialized with Emoji2Vec weights.\n",
      "'🔥' initialized with Emoji2Vec weights.\n",
      "'👍' initialized with Emoji2Vec weights.\n",
      "'😭' initialized with Emoji2Vec weights.\n",
      "'🙏' initialized with Emoji2Vec weights.\n",
      "'🥺' initialized with random weights.\n",
      "'😍' initialized with Emoji2Vec weights.\n",
      "'😅' initialized with Emoji2Vec weights.\n"
     ]
    }
   ],
   "source": [
    "for emoji in emoji_list:\n",
    "    token_index = tokenizer.convert_tokens_to_ids(emoji)\n",
    "    if emoji in e2v.key_to_index:\n",
    "        print(f\"'{emoji}' initialized with Emoji2Vec weights.\")\n",
    "    else:\n",
    "        print(f\"'{emoji}' initialized with random weights.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for '😀': tensor([ 0.0116, -0.0169,  0.0395, -0.0076,  0.0237])\n",
      "Embedding for '😂': tensor([ 0.0213,  0.0384,  0.0585, -0.0085, -0.0127])\n",
      "Embedding for '❤️': tensor([ 0.0173,  0.0480,  0.0604, -0.0098,  0.0586])\n",
      "Embedding for '🔥': tensor([ 0.0571,  0.0239,  0.0397, -0.0350,  0.0097])\n",
      "Embedding for '👍': tensor([ 0.0179,  0.0478,  0.0260, -0.0198,  0.0233])\n",
      "Embedding for '😭': tensor([ 0.0044,  0.0139,  0.0420, -0.0062, -0.0175])\n",
      "Embedding for '🙏': tensor([-0.0031,  0.0013,  0.0230, -0.0215, -0.0086])\n",
      "Embedding for '🥺': tensor([-0.0629,  1.5145,  0.4056,  0.2759,  1.2953])\n",
      "Embedding for '😍': tensor([ 0.0656,  0.0093,  0.0686, -0.0363,  0.0171])\n",
      "Embedding for '😅': tensor([-0.0297,  0.0415,  0.0760, -0.0487, -0.0274])\n"
     ]
    }
   ],
   "source": [
    "for emoji in emoji_list:\n",
    "    token_index = tokenizer.convert_tokens_to_ids(emoji)\n",
    "    embedding_vector = embedding_layer.weight.data[token_index]\n",
    "    print(f\"Embedding for '{emoji}': {embedding_vector[:5]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
