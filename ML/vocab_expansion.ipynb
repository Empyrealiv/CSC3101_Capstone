{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rey32\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserting slang into BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TORCH_SEED = 69\n",
    "torch.manual_seed(TORCH_SEED)\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\", output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1193514 word vectors from GloVe.\n"
     ]
    }
   ],
   "source": [
    "def load_glove_embeddings(file_path):\n",
    "    embeddings_index = {}\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = vector\n",
    "    \n",
    "    print(f\"Loaded {len(embeddings_index)} word vectors from GloVe.\")\n",
    "    return embeddings_index\n",
    "\n",
    "file_path = 'Embeddings/glove.twitter.27B/glove.twitter.27B.200d.txt'\n",
    "glove_embeddings = load_glove_embeddings(file_path)\n",
    "GLOVE_EMBEDDING_SIZE = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lol',\n",
       " 'im',\n",
       " 'oh',\n",
       " 'u',\n",
       " 'bio',\n",
       " 'wow',\n",
       " 'omg',\n",
       " 'ur',\n",
       " 'ya',\n",
       " 'pm',\n",
       " 'pic',\n",
       " 'dm',\n",
       " 'btw',\n",
       " 'gt',\n",
       " 'bbq',\n",
       " 'app',\n",
       " 'lmao',\n",
       " 'xd',\n",
       " 'k',\n",
       " 'ppl',\n",
       " 'wtf',\n",
       " 'rip',\n",
       " 'bday',\n",
       " 'idk',\n",
       " 'thx',\n",
       " 'sis',\n",
       " 'vip',\n",
       " 'bb',\n",
       " 'ooh',\n",
       " 'plz',\n",
       " 'sir',\n",
       " 'yr',\n",
       " 'fml',\n",
       " 'fam',\n",
       " 'bf',\n",
       " 'peeps',\n",
       " 'jk',\n",
       " 'wat',\n",
       " 'pls',\n",
       " 'atm',\n",
       " 'asap',\n",
       " 'smh',\n",
       " 'aka',\n",
       " 'bff',\n",
       " 'fab',\n",
       " 'ily',\n",
       " 'gf',\n",
       " 'mid',\n",
       " 'meh',\n",
       " 'abt',\n",
       " 'lmfao',\n",
       " 'ty',\n",
       " 'ff',\n",
       " 'fyi',\n",
       " 'tht',\n",
       " 'sux',\n",
       " 'goat',\n",
       " 'ftw',\n",
       " 'lit',\n",
       " 'probs',\n",
       " 'cap',\n",
       " 'piss',\n",
       " 'prolly',\n",
       " 'msg',\n",
       " 'tbh',\n",
       " 'thnx',\n",
       " 'cam',\n",
       " 'nc',\n",
       " 'omfg',\n",
       " 'gd',\n",
       " 'rofl',\n",
       " 'gal',\n",
       " 'wth',\n",
       " 'dis',\n",
       " 'tgif',\n",
       " 'nw',\n",
       " 'sry',\n",
       " 'admin',\n",
       " 'imo',\n",
       " 'mc',\n",
       " 'gud',\n",
       " 'op',\n",
       " 'hv',\n",
       " 'bak',\n",
       " 'ratio',\n",
       " 'drip',\n",
       " 'wah',\n",
       " 'gg',\n",
       " 'ig',\n",
       " 'veg',\n",
       " 'wrk',\n",
       " 'eva',\n",
       " 'bot',\n",
       " 'ttyl',\n",
       " 'fu',\n",
       " 'mb',\n",
       " 'nt',\n",
       " 'fr',\n",
       " 'inc',\n",
       " 'rly',\n",
       " 'np',\n",
       " 'ss',\n",
       " 'ot',\n",
       " 'brb',\n",
       " 'tu',\n",
       " 'smash',\n",
       " 'srsly',\n",
       " 'mod',\n",
       " 'pos',\n",
       " 'chad',\n",
       " 'af',\n",
       " 'kk',\n",
       " 'gna',\n",
       " 'sup',\n",
       " 'gnite',\n",
       " 'gnight',\n",
       " 'wut',\n",
       " 'sheesh',\n",
       " 'yt',\n",
       " 'cya',\n",
       " 'swag',\n",
       " 'kia',\n",
       " 'ffs',\n",
       " 'xoxoxo',\n",
       " 'ly',\n",
       " 'yaa',\n",
       " 'irl',\n",
       " 'dw',\n",
       " 'pst',\n",
       " 'ick',\n",
       " 'imho',\n",
       " 'flex',\n",
       " 'ciao',\n",
       " 'cmon',\n",
       " 'nvm',\n",
       " 'zomg',\n",
       " 'kewl',\n",
       " 'bbl',\n",
       " 'paw',\n",
       " 'stan',\n",
       " 'psa',\n",
       " 'aight',\n",
       " 'bloke',\n",
       " 'eta',\n",
       " 'ikr',\n",
       " 'gh',\n",
       " 'nvr',\n",
       " 'wuz',\n",
       " 'mgmt',\n",
       " 'ik',\n",
       " 'arc',\n",
       " 'finna',\n",
       " 'sos',\n",
       " 'wb',\n",
       " 'lik',\n",
       " 'og',\n",
       " 'hawt',\n",
       " 'enuf',\n",
       " 'gl',\n",
       " 'gtg',\n",
       " 'selfie',\n",
       " 'zzzz',\n",
       " 'totes',\n",
       " 'acc',\n",
       " 'dank',\n",
       " 'eg',\n",
       " 'noob',\n",
       " 'idc',\n",
       " 'thot',\n",
       " 'wbu',\n",
       " 'otw',\n",
       " 'ez',\n",
       " 'cld',\n",
       " 'stfu',\n",
       " 'obv',\n",
       " 'omw',\n",
       " 'gn',\n",
       " 'kms',\n",
       " 'yas',\n",
       " 'ofc',\n",
       " 'chk',\n",
       " 'ilu',\n",
       " 'bae',\n",
       " 'downvote',\n",
       " 'lulz',\n",
       " 'boyf',\n",
       " 'ic',\n",
       " 'mehh',\n",
       " 'nsfw',\n",
       " 'roflmao',\n",
       " 'pov',\n",
       " 'bcos',\n",
       " 'gtfo',\n",
       " 'gratz',\n",
       " 'rotfl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slang_df = pd.read_csv('Vocabulary/slang_words_final.csv', header=None, names=['slang'])\n",
    "slang_list = slang_df['slang'].tolist()\n",
    "slang_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized 'lol' with projected GloVe weights.\n",
      "Initialized 'omg' with projected GloVe weights.\n",
      "Initialized 'dm' with projected GloVe weights.\n",
      "Initialized 'btw' with projected GloVe weights.\n",
      "Initialized 'bbq' with projected GloVe weights.\n",
      "Initialized 'lmao' with projected GloVe weights.\n",
      "Initialized 'xd' with projected GloVe weights.\n",
      "Initialized 'ppl' with projected GloVe weights.\n",
      "Initialized 'wtf' with projected GloVe weights.\n",
      "Initialized 'bday' with projected GloVe weights.\n",
      "Initialized 'idk' with projected GloVe weights.\n",
      "Initialized 'thx' with projected GloVe weights.\n",
      "Initialized 'ooh' with projected GloVe weights.\n",
      "Initialized 'plz' with projected GloVe weights.\n",
      "Initialized 'yr' with projected GloVe weights.\n",
      "Initialized 'fml' with projected GloVe weights.\n",
      "Initialized 'fam' with projected GloVe weights.\n",
      "Initialized 'peeps' with projected GloVe weights.\n",
      "Initialized 'jk' with projected GloVe weights.\n",
      "Initialized 'pls' with projected GloVe weights.\n",
      "Initialized 'asap' with projected GloVe weights.\n",
      "Initialized 'smh' with projected GloVe weights.\n",
      "Initialized 'bff' with projected GloVe weights.\n",
      "Initialized 'fab' with projected GloVe weights.\n",
      "Initialized 'ily' with projected GloVe weights.\n",
      "Initialized 'gf' with projected GloVe weights.\n",
      "Initialized 'meh' with projected GloVe weights.\n",
      "Initialized 'abt' with projected GloVe weights.\n",
      "Initialized 'lmfao' with projected GloVe weights.\n",
      "Initialized 'fyi' with projected GloVe weights.\n",
      "Initialized 'tht' with projected GloVe weights.\n",
      "Initialized 'sux' with projected GloVe weights.\n",
      "Initialized 'ftw' with projected GloVe weights.\n",
      "Initialized 'probs' with projected GloVe weights.\n",
      "Initialized 'prolly' with projected GloVe weights.\n",
      "Initialized 'msg' with projected GloVe weights.\n",
      "Initialized 'tbh' with projected GloVe weights.\n",
      "Initialized 'thnx' with projected GloVe weights.\n",
      "Initialized 'omfg' with projected GloVe weights.\n",
      "Initialized 'gd' with projected GloVe weights.\n",
      "Initialized 'rofl' with projected GloVe weights.\n",
      "Initialized 'wth' with projected GloVe weights.\n",
      "Initialized 'dis' with projected GloVe weights.\n",
      "Initialized 'tgif' with projected GloVe weights.\n",
      "Initialized 'sry' with projected GloVe weights.\n",
      "Initialized 'admin' with projected GloVe weights.\n",
      "Initialized 'imo' with projected GloVe weights.\n",
      "Initialized 'gud' with projected GloVe weights.\n",
      "Initialized 'hv' with projected GloVe weights.\n",
      "Initialized 'bak' with projected GloVe weights.\n",
      "Initialized 'gg' with projected GloVe weights.\n",
      "Initialized 'ig' with projected GloVe weights.\n",
      "Initialized 'veg' with projected GloVe weights.\n",
      "Initialized 'wrk' with projected GloVe weights.\n",
      "Initialized 'ttyl' with projected GloVe weights.\n",
      "Initialized 'rly' with projected GloVe weights.\n",
      "Initialized 'brb' with projected GloVe weights.\n",
      "Initialized 'srsly' with projected GloVe weights.\n",
      "Initialized 'pos' with projected GloVe weights.\n",
      "Initialized 'kk' with projected GloVe weights.\n",
      "Initialized 'gna' with projected GloVe weights.\n",
      "Initialized 'sup' with projected GloVe weights.\n",
      "Initialized 'gnite' with projected GloVe weights.\n",
      "Initialized 'gnight' with projected GloVe weights.\n",
      "Initialized 'wut' with projected GloVe weights.\n",
      "Initialized 'sheesh' with projected GloVe weights.\n",
      "Initialized 'yt' with projected GloVe weights.\n",
      "Initialized 'cya' with projected GloVe weights.\n",
      "Initialized 'swag' with projected GloVe weights.\n",
      "Initialized 'ffs' with projected GloVe weights.\n",
      "Initialized 'xoxoxo' with projected GloVe weights.\n",
      "Initialized 'ly' with projected GloVe weights.\n",
      "Initialized 'yaa' with projected GloVe weights.\n",
      "Initialized 'irl' with projected GloVe weights.\n",
      "Initialized 'dw' with projected GloVe weights.\n",
      "Initialized 'pst' with projected GloVe weights.\n",
      "Initialized 'ick' with projected GloVe weights.\n",
      "Initialized 'imho' with projected GloVe weights.\n",
      "Initialized 'ciao' with projected GloVe weights.\n",
      "Initialized 'cmon' with projected GloVe weights.\n",
      "Initialized 'nvm' with projected GloVe weights.\n",
      "Initialized 'zomg' with projected GloVe weights.\n",
      "Initialized 'kewl' with projected GloVe weights.\n",
      "Initialized 'bbl' with projected GloVe weights.\n",
      "Initialized 'psa' with projected GloVe weights.\n",
      "Initialized 'aight' with projected GloVe weights.\n",
      "Initialized 'bloke' with projected GloVe weights.\n",
      "Initialized 'ikr' with projected GloVe weights.\n",
      "Initialized 'gh' with projected GloVe weights.\n",
      "Initialized 'nvr' with projected GloVe weights.\n",
      "Initialized 'wuz' with projected GloVe weights.\n",
      "Initialized 'mgmt' with projected GloVe weights.\n",
      "Initialized 'finna' with projected GloVe weights.\n",
      "Initialized 'sos' with projected GloVe weights.\n",
      "Initialized 'lik' with projected GloVe weights.\n",
      "Initialized 'hawt' with projected GloVe weights.\n",
      "Initialized 'enuf' with projected GloVe weights.\n",
      "Initialized 'gl' with projected GloVe weights.\n",
      "Initialized 'gtg' with projected GloVe weights.\n",
      "Initialized 'selfie' with projected GloVe weights.\n",
      "Initialized 'zzzz' with projected GloVe weights.\n",
      "Initialized 'totes' with projected GloVe weights.\n",
      "Initialized 'dank' with projected GloVe weights.\n",
      "Initialized 'eg' with projected GloVe weights.\n",
      "Initialized 'noob' with projected GloVe weights.\n",
      "Initialized 'idc' with projected GloVe weights.\n",
      "Initialized 'thot' with projected GloVe weights.\n",
      "Initialized 'wbu' with projected GloVe weights.\n",
      "Initialized 'otw' with projected GloVe weights.\n",
      "Initialized 'ez' with projected GloVe weights.\n",
      "Initialized 'cld' with projected GloVe weights.\n",
      "Initialized 'stfu' with projected GloVe weights.\n",
      "Initialized 'obv' with projected GloVe weights.\n",
      "Initialized 'omw' with projected GloVe weights.\n",
      "Initialized 'gn' with projected GloVe weights.\n",
      "Initialized 'kms' with projected GloVe weights.\n",
      "Initialized 'yas' with projected GloVe weights.\n",
      "Initialized 'ofc' with projected GloVe weights.\n",
      "Initialized 'chk' with projected GloVe weights.\n",
      "Initialized 'ilu' with projected GloVe weights.\n",
      "Initialized 'downvote' with random weights.\n",
      "Initialized 'lulz' with projected GloVe weights.\n",
      "Initialized 'boyf' with projected GloVe weights.\n",
      "Initialized 'mehh' with projected GloVe weights.\n",
      "Initialized 'nsfw' with projected GloVe weights.\n",
      "Initialized 'roflmao' with projected GloVe weights.\n",
      "Initialized 'pov' with projected GloVe weights.\n",
      "Initialized 'bcos' with projected GloVe weights.\n",
      "Initialized 'gtfo' with projected GloVe weights.\n",
      "Initialized 'gratz' with projected GloVe weights.\n",
      "Initialized 'rotfl' with projected GloVe weights.\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.embeddings.word_embeddings\n",
    "\n",
    "slang_projection_layer = torch.nn.Linear(GLOVE_EMBEDDING_SIZE, model.config.hidden_size)\n",
    "\n",
    "new_slang_tokens = [token for token in slang_list if token not in tokenizer.get_vocab()]\n",
    "tokenizer.add_tokens(new_slang_tokens)\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "for slang in new_slang_tokens:\n",
    "    token_index = tokenizer.convert_tokens_to_ids(slang)\n",
    "    \n",
    "    if slang in glove_embeddings:\n",
    "        glove_vector = torch.tensor(glove_embeddings[slang], dtype=torch.float32)\n",
    "        projected_vector = slang_projection_layer(glove_vector.unsqueeze(0)).squeeze(0)\n",
    "        embedding_layer.weight.data[token_index] = projected_vector\n",
    "        print(f\"Initialized '{slang}' with projected GloVe weights.\")\n",
    "    else:\n",
    "        embedding_layer.weight.data[token_index] = torch.randn(model.config.hidden_size)\n",
    "        print(f\"Initialized '{slang}' with random weights.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'lol' successfully added to the tokenizer with index 30522.\n",
      "'omg' successfully added to the tokenizer with index 30523.\n",
      "'dm' successfully added to the tokenizer with index 30524.\n",
      "'btw' successfully added to the tokenizer with index 30525.\n",
      "'bbq' successfully added to the tokenizer with index 30526.\n",
      "'lmao' successfully added to the tokenizer with index 30527.\n",
      "'xd' successfully added to the tokenizer with index 30528.\n",
      "'ppl' successfully added to the tokenizer with index 30529.\n",
      "'wtf' successfully added to the tokenizer with index 30530.\n",
      "'bday' successfully added to the tokenizer with index 30531.\n",
      "'idk' successfully added to the tokenizer with index 30532.\n",
      "'thx' successfully added to the tokenizer with index 30533.\n",
      "'ooh' successfully added to the tokenizer with index 30534.\n",
      "'plz' successfully added to the tokenizer with index 30535.\n",
      "'yr' successfully added to the tokenizer with index 30536.\n",
      "'fml' successfully added to the tokenizer with index 30537.\n",
      "'fam' successfully added to the tokenizer with index 30538.\n",
      "'peeps' successfully added to the tokenizer with index 30539.\n",
      "'jk' successfully added to the tokenizer with index 30540.\n",
      "'pls' successfully added to the tokenizer with index 30541.\n",
      "'asap' successfully added to the tokenizer with index 30542.\n",
      "'smh' successfully added to the tokenizer with index 30543.\n",
      "'bff' successfully added to the tokenizer with index 30544.\n",
      "'fab' successfully added to the tokenizer with index 30545.\n",
      "'ily' successfully added to the tokenizer with index 30546.\n",
      "'gf' successfully added to the tokenizer with index 30547.\n",
      "'meh' successfully added to the tokenizer with index 30548.\n",
      "'abt' successfully added to the tokenizer with index 30549.\n",
      "'lmfao' successfully added to the tokenizer with index 30550.\n",
      "'fyi' successfully added to the tokenizer with index 30551.\n",
      "'tht' successfully added to the tokenizer with index 30552.\n",
      "'sux' successfully added to the tokenizer with index 30553.\n",
      "'ftw' successfully added to the tokenizer with index 30554.\n",
      "'probs' successfully added to the tokenizer with index 30555.\n",
      "'prolly' successfully added to the tokenizer with index 30556.\n",
      "'msg' successfully added to the tokenizer with index 30557.\n",
      "'tbh' successfully added to the tokenizer with index 30558.\n",
      "'thnx' successfully added to the tokenizer with index 30559.\n",
      "'omfg' successfully added to the tokenizer with index 30560.\n",
      "'gd' successfully added to the tokenizer with index 30561.\n",
      "'rofl' successfully added to the tokenizer with index 30562.\n",
      "'wth' successfully added to the tokenizer with index 30563.\n",
      "'dis' successfully added to the tokenizer with index 30564.\n",
      "'tgif' successfully added to the tokenizer with index 30565.\n",
      "'sry' successfully added to the tokenizer with index 30566.\n",
      "'admin' successfully added to the tokenizer with index 30567.\n",
      "'imo' successfully added to the tokenizer with index 30568.\n",
      "'gud' successfully added to the tokenizer with index 30569.\n",
      "'hv' successfully added to the tokenizer with index 30570.\n",
      "'bak' successfully added to the tokenizer with index 30571.\n",
      "'gg' successfully added to the tokenizer with index 30572.\n",
      "'ig' successfully added to the tokenizer with index 30573.\n",
      "'veg' successfully added to the tokenizer with index 30574.\n",
      "'wrk' successfully added to the tokenizer with index 30575.\n",
      "'ttyl' successfully added to the tokenizer with index 30576.\n",
      "'rly' successfully added to the tokenizer with index 30577.\n",
      "'brb' successfully added to the tokenizer with index 30578.\n",
      "'srsly' successfully added to the tokenizer with index 30579.\n",
      "'pos' successfully added to the tokenizer with index 30580.\n",
      "'kk' successfully added to the tokenizer with index 30581.\n",
      "'gna' successfully added to the tokenizer with index 30582.\n",
      "'sup' successfully added to the tokenizer with index 30583.\n",
      "'gnite' successfully added to the tokenizer with index 30584.\n",
      "'gnight' successfully added to the tokenizer with index 30585.\n",
      "'wut' successfully added to the tokenizer with index 30586.\n",
      "'sheesh' successfully added to the tokenizer with index 30587.\n",
      "'yt' successfully added to the tokenizer with index 30588.\n",
      "'cya' successfully added to the tokenizer with index 30589.\n",
      "'swag' successfully added to the tokenizer with index 30590.\n",
      "'ffs' successfully added to the tokenizer with index 30591.\n",
      "'xoxoxo' successfully added to the tokenizer with index 30592.\n",
      "'ly' successfully added to the tokenizer with index 30593.\n",
      "'yaa' successfully added to the tokenizer with index 30594.\n",
      "'irl' successfully added to the tokenizer with index 30595.\n",
      "'dw' successfully added to the tokenizer with index 30596.\n",
      "'pst' successfully added to the tokenizer with index 30597.\n",
      "'ick' successfully added to the tokenizer with index 30598.\n",
      "'imho' successfully added to the tokenizer with index 30599.\n",
      "'ciao' successfully added to the tokenizer with index 30600.\n",
      "'cmon' successfully added to the tokenizer with index 30601.\n",
      "'nvm' successfully added to the tokenizer with index 30602.\n",
      "'zomg' successfully added to the tokenizer with index 30603.\n",
      "'kewl' successfully added to the tokenizer with index 30604.\n",
      "'bbl' successfully added to the tokenizer with index 30605.\n",
      "'psa' successfully added to the tokenizer with index 30606.\n",
      "'aight' successfully added to the tokenizer with index 30607.\n",
      "'bloke' successfully added to the tokenizer with index 30608.\n",
      "'ikr' successfully added to the tokenizer with index 30609.\n",
      "'gh' successfully added to the tokenizer with index 30610.\n",
      "'nvr' successfully added to the tokenizer with index 30611.\n",
      "'wuz' successfully added to the tokenizer with index 30612.\n",
      "'mgmt' successfully added to the tokenizer with index 30613.\n",
      "'finna' successfully added to the tokenizer with index 30614.\n",
      "'sos' successfully added to the tokenizer with index 30615.\n",
      "'lik' successfully added to the tokenizer with index 30616.\n",
      "'hawt' successfully added to the tokenizer with index 30617.\n",
      "'enuf' successfully added to the tokenizer with index 30618.\n",
      "'gl' successfully added to the tokenizer with index 30619.\n",
      "'gtg' successfully added to the tokenizer with index 30620.\n",
      "'selfie' successfully added to the tokenizer with index 30621.\n",
      "'zzzz' successfully added to the tokenizer with index 30622.\n",
      "'totes' successfully added to the tokenizer with index 30623.\n",
      "'dank' successfully added to the tokenizer with index 30624.\n",
      "'eg' successfully added to the tokenizer with index 30625.\n",
      "'noob' successfully added to the tokenizer with index 30626.\n",
      "'idc' successfully added to the tokenizer with index 30627.\n",
      "'thot' successfully added to the tokenizer with index 30628.\n",
      "'wbu' successfully added to the tokenizer with index 30629.\n",
      "'otw' successfully added to the tokenizer with index 30630.\n",
      "'ez' successfully added to the tokenizer with index 30631.\n",
      "'cld' successfully added to the tokenizer with index 30632.\n",
      "'stfu' successfully added to the tokenizer with index 30633.\n",
      "'obv' successfully added to the tokenizer with index 30634.\n",
      "'omw' successfully added to the tokenizer with index 30635.\n",
      "'gn' successfully added to the tokenizer with index 30636.\n",
      "'kms' successfully added to the tokenizer with index 30637.\n",
      "'yas' successfully added to the tokenizer with index 30638.\n",
      "'ofc' successfully added to the tokenizer with index 30639.\n",
      "'chk' successfully added to the tokenizer with index 30640.\n",
      "'ilu' successfully added to the tokenizer with index 30641.\n",
      "'downvote' successfully added to the tokenizer with index 30642.\n",
      "'lulz' successfully added to the tokenizer with index 30643.\n",
      "'boyf' successfully added to the tokenizer with index 30644.\n",
      "'mehh' successfully added to the tokenizer with index 30645.\n",
      "'nsfw' successfully added to the tokenizer with index 30646.\n",
      "'roflmao' successfully added to the tokenizer with index 30647.\n",
      "'pov' successfully added to the tokenizer with index 30648.\n",
      "'bcos' successfully added to the tokenizer with index 30649.\n",
      "'gtfo' successfully added to the tokenizer with index 30650.\n",
      "'gratz' successfully added to the tokenizer with index 30651.\n",
      "'rotfl' successfully added to the tokenizer with index 30652.\n"
     ]
    }
   ],
   "source": [
    "for slang in new_slang_tokens:\n",
    "    token_index = tokenizer.convert_tokens_to_ids(slang)\n",
    "    if token_index != tokenizer.unk_token_id:\n",
    "        print(f\"'{slang}' successfully added to the tokenizer with index {token_index}.\")\n",
    "    else:\n",
    "        print(f\"'{slang}' was not added to the tokenizer.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for 'lol': tensor([-0.3706, -0.1505, -0.7883,  0.1622,  0.0539])\n",
      "Embedding for 'omg': tensor([-0.1702, -0.0533, -0.7506,  0.0376,  0.2117])\n",
      "Embedding for 'dm': tensor([-0.0391, -0.2768, -0.3481,  0.1401,  0.3842])\n",
      "Embedding for 'btw': tensor([-0.1023, -0.0513, -0.6508, -0.0574, -0.0829])\n",
      "Embedding for 'bbq': tensor([-0.4082,  0.2432, -0.3136,  0.0752,  0.1574])\n",
      "Embedding for 'lmao': tensor([-0.4083, -0.1617, -0.7171,  0.1970,  0.0265])\n",
      "Embedding for 'xd': tensor([-0.1308, -0.0710, -0.8332,  0.1608,  0.3912])\n",
      "Embedding for 'ppl': tensor([ 0.0139, -0.2509, -0.3698, -0.1251, -0.2624])\n",
      "Embedding for 'wtf': tensor([-0.0329, -0.1454, -0.5358,  0.3138,  0.2205])\n",
      "Embedding for 'bday': tensor([-0.2101,  0.3776, -0.9609, -0.2693, -0.0524])\n",
      "Embedding for 'idk': tensor([-0.0946, -0.1980, -0.8532,  0.0479,  0.0510])\n",
      "Embedding for 'thx': tensor([-0.1844, -0.4793, -0.5281, -0.1230, -0.1984])\n",
      "Embedding for 'ooh': tensor([-0.0421, -0.3134, -0.5394,  0.1425,  0.2673])\n",
      "Embedding for 'plz': tensor([ 0.0547, -0.1943, -0.2175, -0.1015,  0.2185])\n",
      "Embedding for 'yr': tensor([-0.1945,  0.0253, -0.5877,  0.0570, -0.1730])\n",
      "Embedding for 'fml': tensor([-0.0787,  0.0117, -0.3497,  0.7108,  0.1303])\n",
      "Embedding for 'fam': tensor([-0.2163, -0.0543, -0.4292, -0.3711,  0.1135])\n",
      "Embedding for 'peeps': tensor([-0.0444,  0.0330, -0.1670, -0.2062, -0.1091])\n",
      "Embedding for 'jk': tensor([-0.2857, -0.0471, -0.6626,  0.3261,  0.2009])\n",
      "Embedding for 'pls': tensor([ 0.0630, -0.2876, -0.4228, -0.1677,  0.2802])\n",
      "Embedding for 'asap': tensor([ 0.3303,  0.0818, -0.2918, -0.0601,  0.0590])\n",
      "Embedding for 'smh': tensor([-0.0540, -0.2150, -0.4711,  0.1596, -0.1452])\n",
      "Embedding for 'bff': tensor([-0.1977,  0.1651, -0.2961,  0.0962,  0.0104])\n",
      "Embedding for 'fab': tensor([-0.0335,  0.0890, -0.3233, -0.3675, -0.1443])\n",
      "Embedding for 'ily': tensor([-0.2045,  0.0264, -0.3967, -0.1681,  0.1136])\n",
      "Embedding for 'gf': tensor([-0.3800, -0.0754, -0.5613,  0.2817, -0.0821])\n",
      "Embedding for 'meh': tensor([ 0.2398, -0.3981, -0.4940, -0.1037, -0.0526])\n",
      "Embedding for 'abt': tensor([-0.1241, -0.2029, -0.6998, -0.3839, -0.0240])\n",
      "Embedding for 'lmfao': tensor([-0.3451, -0.1413, -0.5557,  0.1899,  0.0521])\n",
      "Embedding for 'fyi': tensor([-0.1121,  0.0092, -0.1126,  0.0934, -0.2477])\n",
      "Embedding for 'tht': tensor([-0.1434, -0.2641, -0.5313, -0.1737, -0.1208])\n",
      "Embedding for 'sux': tensor([ 0.1855, -0.1069, -0.3239, -0.0972,  0.1058])\n",
      "Embedding for 'ftw': tensor([-0.1836,  0.0366, -0.0989,  0.1402,  0.0235])\n",
      "Embedding for 'probs': tensor([-0.2384,  0.2489, -0.2622,  0.4936,  0.2591])\n",
      "Embedding for 'prolly': tensor([-0.1666,  0.0932, -0.5024,  0.1266, -0.2136])\n",
      "Embedding for 'msg': tensor([-0.0366, -0.1615, -0.4224,  0.3459,  0.1124])\n",
      "Embedding for 'tbh': tensor([-0.1374,  0.1418, -0.3762, -0.0937,  0.1604])\n",
      "Embedding for 'thnx': tensor([-0.2028, -0.3405, -0.5530, -0.3344,  0.0654])\n",
      "Embedding for 'omfg': tensor([-0.1125, -0.0637, -0.5180,  0.1192,  0.1407])\n",
      "Embedding for 'gd': tensor([-0.1574, -0.1835, -0.6458,  0.0032, -0.0913])\n",
      "Embedding for 'rofl': tensor([-0.2479,  0.0097, -0.1426,  0.2802, -0.4151])\n",
      "Embedding for 'wth': tensor([-0.1540, -0.1818, -0.5621, -0.0084, -0.0132])\n",
      "Embedding for 'dis': tensor([-0.0196, -0.3525, -0.7281, -0.3875, -0.0031])\n",
      "Embedding for 'tgif': tensor([-0.1360,  0.2302, -0.5914, -0.1391,  0.1129])\n",
      "Embedding for 'sry': tensor([-3.9738e-04, -3.0719e-01, -6.0801e-01, -5.0108e-02,  4.3412e-02])\n",
      "Embedding for 'admin': tensor([-0.1067, -0.2558,  0.0421,  0.1427, -0.1990])\n",
      "Embedding for 'imo': tensor([-0.1643, -0.0295, -0.3429, -0.0304, -0.0667])\n",
      "Embedding for 'gud': tensor([-0.0146, -0.5095, -0.8796, -0.2051, -0.0011])\n",
      "Embedding for 'hv': tensor([-0.1095, -0.0730, -0.6292, -0.1569, -0.0276])\n",
      "Embedding for 'bak': tensor([ 0.2089, -0.1281, -0.7504,  0.1899,  0.4002])\n",
      "Embedding for 'gg': tensor([-0.1062, -0.0663, -0.3860,  0.0783,  0.0492])\n",
      "Embedding for 'ig': tensor([ 0.0999, -0.3518, -0.1617,  0.1756, -0.2431])\n",
      "Embedding for 'veg': tensor([-0.1382,  0.1311, -0.1224,  0.3290, -0.0720])\n",
      "Embedding for 'wrk': tensor([-0.0825, -0.2765, -0.4620, -0.0148, -0.0658])\n",
      "Embedding for 'ttyl': tensor([-0.3180, -0.0800,  0.0481,  0.0031,  0.1547])\n",
      "Embedding for 'rly': tensor([ 0.0045, -0.2241, -0.5534, -0.2690, -0.0215])\n",
      "Embedding for 'brb': tensor([-0.1997,  0.1752,  0.0786,  0.0686,  0.0583])\n",
      "Embedding for 'srsly': tensor([ 0.0833, -0.0595, -0.5057, -0.0381,  0.1854])\n",
      "Embedding for 'pos': tensor([-0.0351, -0.0656, -0.2627,  0.3780,  0.0586])\n",
      "Embedding for 'kk': tensor([ 0.1240,  0.1963, -0.3657,  0.1333,  0.1257])\n",
      "Embedding for 'gna': tensor([-0.3768,  0.1710, -0.5502, -0.0106,  0.1685])\n",
      "Embedding for 'sup': tensor([-0.1138, -0.4897, -0.5982,  0.0805,  0.0099])\n",
      "Embedding for 'gnite': tensor([ 0.0565, -0.3194, -0.1431, -0.4604, -0.2305])\n",
      "Embedding for 'gnight': tensor([-0.0520, -0.2813,  0.0144, -0.3653, -0.1199])\n",
      "Embedding for 'wut': tensor([-0.3349, -0.2911, -0.5290,  0.1084,  0.2190])\n",
      "Embedding for 'sheesh': tensor([ 0.0504, -0.0048, -0.4312,  0.0619, -0.1011])\n",
      "Embedding for 'yt': tensor([-0.1392, -0.3580, -0.1791,  0.1513, -0.0346])\n",
      "Embedding for 'cya': tensor([-0.2436,  0.1563, -0.4477, -0.0509,  0.4064])\n",
      "Embedding for 'swag': tensor([ 0.0407,  0.1419, -0.0982,  0.2545, -0.1442])\n",
      "Embedding for 'ffs': tensor([-0.1378, -0.0716, -0.3128,  0.2081,  0.4383])\n",
      "Embedding for 'xoxoxo': tensor([-0.3663, -0.1030, -0.2636, -0.2747,  0.2138])\n",
      "Embedding for 'ly': tensor([-0.2997, -0.0628, -0.3885,  0.0717,  0.3288])\n",
      "Embedding for 'yaa': tensor([-0.1206, -0.2020, -0.6389,  0.1934,  0.1030])\n",
      "Embedding for 'irl': tensor([ 0.1948,  0.0686, -0.2064,  0.0535, -0.1142])\n",
      "Embedding for 'dw': tensor([-0.1614, -0.2491, -0.6861,  0.1373,  0.3974])\n",
      "Embedding for 'pst': tensor([-0.3523,  0.0241, -0.5568,  0.1645, -0.2569])\n",
      "Embedding for 'ick': tensor([ 0.0476, -0.1362, -0.3527, -0.1341,  0.0877])\n",
      "Embedding for 'imho': tensor([-0.0203,  0.1553, -0.0315, -0.1132, -0.1021])\n",
      "Embedding for 'ciao': tensor([-0.0715, -0.4420,  0.2096, -0.0051,  0.1322])\n",
      "Embedding for 'cmon': tensor([ 0.0858, -0.0428, -0.3081,  0.0348,  0.1778])\n",
      "Embedding for 'nvm': tensor([-0.2482, -0.2710, -0.7836, -0.0492,  0.1246])\n",
      "Embedding for 'zomg': tensor([-0.2206,  0.1675, -0.2676, -0.0774, -0.0194])\n",
      "Embedding for 'kewl': tensor([-0.1170, -0.0124, -0.2650, -0.2914, -0.1071])\n",
      "Embedding for 'bbl': tensor([-0.2281, -0.0471,  0.1280, -0.0531,  0.2947])\n",
      "Embedding for 'psa': tensor([-0.2700,  0.1198, -0.2790,  0.3544, -0.0860])\n",
      "Embedding for 'aight': tensor([-0.2070, -0.0338, -0.5072, -0.1595,  0.0487])\n",
      "Embedding for 'bloke': tensor([ 0.0701,  0.0281, -0.1791,  0.2284,  0.1650])\n",
      "Embedding for 'ikr': tensor([-0.2099, -0.1052, -0.8573, -0.1684,  0.1112])\n",
      "Embedding for 'gh': tensor([-0.0786, -0.0266,  0.0740,  0.2639,  0.5883])\n",
      "Embedding for 'nvr': tensor([-0.0069, -0.1040, -0.5245, -0.0568, -0.1395])\n",
      "Embedding for 'wuz': tensor([-0.0532, -0.5177, -0.4592, -0.2697,  0.1427])\n",
      "Embedding for 'mgmt': tensor([ 0.0706, -0.1630, -0.0921, -0.1795,  0.0157])\n",
      "Embedding for 'finna': tensor([-0.1118, -0.0731, -0.3102, -0.0356, -0.1212])\n",
      "Embedding for 'sos': tensor([ 0.2257,  0.3280, -0.4512,  0.4752,  0.0044])\n",
      "Embedding for 'lik': tensor([-0.0539, -0.2772, -0.4279, -0.1313,  0.0090])\n",
      "Embedding for 'hawt': tensor([-0.1468,  0.0329, -0.2681, -0.4728, -0.0217])\n",
      "Embedding for 'enuf': tensor([-0.1549, -0.1506, -0.5969,  0.0427,  0.1468])\n",
      "Embedding for 'gl': tensor([-0.2702,  0.1645, -0.2470, -0.1229,  0.4329])\n",
      "Embedding for 'gtg': tensor([-0.1226, -0.0685, -0.1045, -0.0151,  0.0045])\n",
      "Embedding for 'selfie': tensor([ 0.0269,  0.1107, -0.2407,  0.2326,  0.1135])\n",
      "Embedding for 'zzzz': tensor([ 0.2479, -0.2882, -0.0380, -0.1256,  0.2034])\n",
      "Embedding for 'totes': tensor([-0.5980,  0.4532, -0.4448,  0.1838, -0.1766])\n",
      "Embedding for 'dank': tensor([-0.1971, -0.0890,  0.0068, -0.1464,  0.2621])\n",
      "Embedding for 'eg': tensor([ 0.2186, -0.2756, -0.1877, -0.1023, -0.0254])\n",
      "Embedding for 'noob': tensor([-0.1397,  0.2010, -0.2093,  0.3047, -0.1041])\n",
      "Embedding for 'idc': tensor([-0.0664,  0.0704, -0.2664, -0.2163,  0.1691])\n",
      "Embedding for 'thot': tensor([ 0.0171, -0.0666, -0.1512,  0.2770,  0.1064])\n",
      "Embedding for 'wbu': tensor([-0.1605,  0.1963, -0.6003,  0.0674,  0.2006])\n",
      "Embedding for 'otw': tensor([ 0.0166,  0.0154, -0.3452, -0.2203, -0.2442])\n",
      "Embedding for 'ez': tensor([-0.0447, -0.2060, -0.3103,  0.5515,  0.0811])\n",
      "Embedding for 'cld': tensor([ 0.0635,  0.1536, -0.3642, -0.1105, -0.0143])\n",
      "Embedding for 'stfu': tensor([-0.1010, -0.0810, -0.4483,  0.1339,  0.5438])\n",
      "Embedding for 'obv': tensor([-0.3860,  0.1011, -0.1680,  0.0339,  0.0977])\n",
      "Embedding for 'omw': tensor([-0.3460, -0.0288, -0.2805, -0.0183,  0.4957])\n",
      "Embedding for 'gn': tensor([-0.1084,  0.0224, -0.1689,  0.1488,  0.3340])\n",
      "Embedding for 'kms': tensor([-0.1134,  0.1437, -0.0754,  0.3439,  0.0281])\n",
      "Embedding for 'yas': tensor([-0.2191,  0.1357, -0.4304, -0.0501,  0.2307])\n",
      "Embedding for 'ofc': tensor([-0.3200,  0.0816, -0.1941, -0.0306,  0.0990])\n",
      "Embedding for 'chk': tensor([-0.0004,  0.0525, -0.1076, -0.2842, -0.0565])\n",
      "Embedding for 'ilu': tensor([-0.1272,  0.0411, -0.4121, -0.1234,  0.1215])\n",
      "Embedding for 'downvote': tensor([-1.4084,  1.3344, -1.6610,  1.2102, -0.6117])\n",
      "Embedding for 'lulz': tensor([-0.1675, -0.0179, -0.3627,  0.1198, -0.0269])\n",
      "Embedding for 'boyf': tensor([-0.2790,  0.0694, -0.4958, -0.3052, -0.0084])\n",
      "Embedding for 'mehh': tensor([ 0.0185, -0.4544, -0.4050, -0.1674,  0.1200])\n",
      "Embedding for 'nsfw': tensor([-0.5283, -0.1925, -0.1232,  0.3247, -0.2647])\n",
      "Embedding for 'roflmao': tensor([-0.0802,  0.1751, -0.3359,  0.1737, -0.0946])\n",
      "Embedding for 'pov': tensor([-0.1682, -0.3565, -0.5783,  0.3582,  0.1077])\n",
      "Embedding for 'bcos': tensor([-0.0710, -0.0286, -0.2783, -0.2457,  0.1980])\n",
      "Embedding for 'gtfo': tensor([ 0.0860, -0.1436, -0.0313,  0.1152,  0.3083])\n",
      "Embedding for 'gratz': tensor([ 0.0305,  0.2041, -0.1869, -0.0955, -0.1366])\n",
      "Embedding for 'rotfl': tensor([-0.2087, -0.0238, -0.3648, -0.0239, -0.0593])\n"
     ]
    }
   ],
   "source": [
    "for slang in new_slang_tokens:\n",
    "    token_index = tokenizer.convert_tokens_to_ids(slang)\n",
    "    if token_index != tokenizer.unk_token_id:\n",
    "        embedding_vector = embedding_layer.weight.data[token_index]\n",
    "        print(f\"Embedding for '{slang}': {embedding_vector[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserting emoji in BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import keyedvectors\n",
    "\n",
    "e2v = keyedvectors.load_word2vec_format('Embeddings/emoji2vec.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of e2v embedding: 300\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dimension of e2v embedding:\", e2v[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "E2V_EMBEDDING_SIZE = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['â¤',\n",
       " 'âœ…',\n",
       " 'ğŸ˜·',\n",
       " 'ğŸ‘‰',\n",
       " 'âœ¨',\n",
       " 'ğŸ’‰',\n",
       " 'âœ”',\n",
       " 'â¡',\n",
       " 'ğŸ™',\n",
       " 'ğŸ“',\n",
       " 'ğŸ¦ ',\n",
       " 'ğŸ‘‡',\n",
       " 'ğŸ“',\n",
       " 'âš ',\n",
       " 'ğŸŒŸ',\n",
       " 'ğŸ˜‚',\n",
       " 'ğŸ’™',\n",
       " 'ğŸ˜Š',\n",
       " 'ğŸŒ',\n",
       " 'ğŸ“¸',\n",
       " 'ğŸ“²',\n",
       " 'ğŸ’ª',\n",
       " 'ğŸ’•',\n",
       " 'â–¶',\n",
       " 'ğŸ”—',\n",
       " 'ğŸ”¥',\n",
       " 'â˜',\n",
       " 'â„¢',\n",
       " 'ğŸ‘',\n",
       " 'ğŸ‰',\n",
       " 'ğŸ˜',\n",
       " 'â­',\n",
       " 'ğŸš¨',\n",
       " 'ğŸ’¯',\n",
       " 'ğŸ™Œ',\n",
       " 'âš•',\n",
       " 'â€¼',\n",
       " 'ğŸ’š',\n",
       " 'ğŸ¥°',\n",
       " 'ğŸ™ğŸ»',\n",
       " 'â—',\n",
       " 'ğŸ’›',\n",
       " 'â™¥',\n",
       " 'ğŸ¤£',\n",
       " 'ğŸ’œ',\n",
       " 'â™€',\n",
       " 'ğŸ©º',\n",
       " 'ğŸ”¹',\n",
       " 'ğŸ“±',\n",
       " 'ğŸ“¢',\n",
       " 'ğŸ‘',\n",
       " 'ğŸ’»',\n",
       " 'ğŸ“§',\n",
       " 'ğŸ“·',\n",
       " 'â˜€',\n",
       " 'ğŸ¥',\n",
       " 'ğŸ¤',\n",
       " 'â–ª',\n",
       " 'âœˆ',\n",
       " 'ğŸ‘©',\n",
       " 'ğŸ¤',\n",
       " 'ğŸ˜‰',\n",
       " 'ğŸ‘€',\n",
       " 'ğŸ˜',\n",
       " 'ğŸŒ',\n",
       " 'ğŸ“Š',\n",
       " 'ğŸ¤©',\n",
       " 'ğŸ¤”',\n",
       " 'ğŸ˜',\n",
       " 'ğŸ¤—',\n",
       " 'ğŸ”¸',\n",
       " 'ğŸ¥³',\n",
       " 'ğŸ§¡',\n",
       " 'ğŸŒˆ',\n",
       " 'ğŸ’«',\n",
       " 'ğŸ‘‰ğŸ»',\n",
       " 'ğŸ“£',\n",
       " 'ğŸ˜ƒ',\n",
       " 'ğŸŒ',\n",
       " 'â¬‡',\n",
       " 'ğŸ§ª',\n",
       " 'âœŒ',\n",
       " 'ğŸ—£',\n",
       " 'ğŸ’–',\n",
       " 'ğŸ™‚',\n",
       " 'â™‚',\n",
       " 'ğŸ“°',\n",
       " 'ğŸ’¥',\n",
       " 'â™¦',\n",
       " 'ğŸ‘†',\n",
       " 'ğŸ‘¨',\n",
       " 'Â®',\n",
       " 'ğŸ“Œ',\n",
       " 'ğŸ™ğŸ¼',\n",
       " 'â˜º',\n",
       " 'ğŸ¤‘',\n",
       " 'ğŸ’¬',\n",
       " 'ğŸ’°',\n",
       " 'ğŸ˜‡',\n",
       " 'ğŸ–¤',\n",
       " 'ğŸŒº',\n",
       " 'ğŸ“š',\n",
       " 'ğŸ¤’',\n",
       " 'âš¡',\n",
       " 'ğŸ””',\n",
       " 'ğŸ¡',\n",
       " 'ğŸ’¡',\n",
       " 'ğŸŒ¿',\n",
       " 'ğŸ˜…',\n",
       " 'ğŸ¤§',\n",
       " 'ğŸŒ¸',\n",
       " 'ğŸ’—',\n",
       " 'ğŸ™ğŸ½',\n",
       " 'ğŸ‘ˆ',\n",
       " 'ğŸ”¬',\n",
       " 'ğŸ ',\n",
       " 'ğŸ˜­',\n",
       " 'ğŸ˜€',\n",
       " 'ğŸ¥',\n",
       " 'â¬†',\n",
       " 'ğŸ”·',\n",
       " 'ğŸ‘¥',\n",
       " 'ğŸƒ',\n",
       " 'ğŸ’Š',\n",
       " 'ğŸ˜˜',\n",
       " 'â˜ğŸ»',\n",
       " 'ğŸ‘£',\n",
       " 'â˜',\n",
       " 'ğŸŒ±',\n",
       " 'ğŸ”´',\n",
       " 'ğŸ˜„',\n",
       " 'ğŸ„',\n",
       " 'â–',\n",
       " 'ğŸ’Œ',\n",
       " 'â°',\n",
       " 'ğŸ“ˆ',\n",
       " 'ğŸ¨',\n",
       " 'ğŸ˜±',\n",
       " 'ğŸš€',\n",
       " 'ğŸ†',\n",
       " 'ğŸ”',\n",
       " 'ğŸ',\n",
       " 'â˜‘',\n",
       " 'ğŸ“©',\n",
       " 'ğŸ’”',\n",
       " 'ğŸ‘‡ğŸ»',\n",
       " 'ğŸ˜¢',\n",
       " 'ğŸ—“',\n",
       " 'ğŸŒ',\n",
       " 'ğŸ‘‹',\n",
       " 'ğŸ™ŒğŸ»',\n",
       " 'ğŸ‡',\n",
       " 'ğŸ©¸',\n",
       " 'ğŸ¦Ÿ',\n",
       " 'ğŸ’ƒ',\n",
       " 'ğŸ‘¹',\n",
       " 'ğŸ‘Œ',\n",
       " 'ğŸ’§',\n",
       " 'ğŸš«',\n",
       " 'âŒ',\n",
       " 'ğŸ™ŒğŸ½',\n",
       " 'ğŸ˜”',\n",
       " 'ğŸ›¡',\n",
       " 'ğŸ¾',\n",
       " 'ğŸ™„',\n",
       " 'ğŸ’ªğŸ»',\n",
       " 'âœ‰',\n",
       " 'ğŸ',\n",
       " 'ğŸŠ',\n",
       " 'âº',\n",
       " 'ğŸ˜³',\n",
       " 'ğŸ«¶',\n",
       " 'ğŸ’',\n",
       " 'ğŸŒ',\n",
       " 'ğŸ˜Œ',\n",
       " 'ğŸ“',\n",
       " 'ğŸˆ',\n",
       " 'ğŸ§¬',\n",
       " 'ğŸŒ»',\n",
       " 'ğŸ©',\n",
       " 'ğŸ•',\n",
       " 'ğŸ§¼',\n",
       " 'ğŸ¤',\n",
       " 'ğŸ©¹',\n",
       " 'âœ',\n",
       " 'ğŸŒ¼',\n",
       " 'â£',\n",
       " 'â„',\n",
       " 'ğŸ›’',\n",
       " 'ğŸ˜‹',\n",
       " 'ğŸ‘Š',\n",
       " 'ğŸ’¼',\n",
       " 'ğŸ’ªğŸ¼',\n",
       " 'ğŸ¦·',\n",
       " 'ğŸŒ´',\n",
       " 'â“',\n",
       " 'ğŸ²',\n",
       " 'ğŸ’',\n",
       " 'ğŸ¶',\n",
       " 'ğŸ‘‰ğŸ¼']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_df = pd.read_csv('Vocabulary/emoji_scores.csv', header=None, names=['emoji', 'score'])\n",
    "emoji_list = emoji_df['emoji'].tolist()[:200]\n",
    "emoji_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized 'â¤' with random weights.\n",
      "Initialized 'âœ…' with projected e2v weights.\n",
      "Initialized 'ğŸ˜·' with projected e2v weights.\n",
      "Initialized 'ğŸ‘‰' with projected e2v weights.\n",
      "Initialized 'âœ¨' with projected e2v weights.\n",
      "Initialized 'ğŸ’‰' with projected e2v weights.\n",
      "Initialized 'âœ”' with random weights.\n",
      "Initialized 'â¡' with random weights.\n",
      "Initialized 'ğŸ™' with projected e2v weights.\n",
      "Initialized 'ğŸ“' with projected e2v weights.\n",
      "Initialized 'ğŸ¦ ' with random weights.\n",
      "Initialized 'ğŸ‘‡' with projected e2v weights.\n",
      "Initialized 'ğŸ“' with projected e2v weights.\n",
      "Initialized 'âš ' with random weights.\n",
      "Initialized 'ğŸŒŸ' with projected e2v weights.\n",
      "Initialized 'ğŸ˜‚' with projected e2v weights.\n",
      "Initialized 'ğŸ’™' with projected e2v weights.\n",
      "Initialized 'ğŸ˜Š' with projected e2v weights.\n",
      "Initialized 'ğŸŒ' with projected e2v weights.\n",
      "Initialized 'ğŸ“¸' with projected e2v weights.\n",
      "Initialized 'ğŸ“²' with projected e2v weights.\n",
      "Initialized 'ğŸ’ª' with projected e2v weights.\n",
      "Initialized 'ğŸ’•' with projected e2v weights.\n",
      "Initialized 'â–¶' with random weights.\n",
      "Initialized 'ğŸ”—' with projected e2v weights.\n",
      "Initialized 'ğŸ”¥' with projected e2v weights.\n",
      "Initialized 'â˜' with random weights.\n",
      "Initialized 'ğŸ‘' with projected e2v weights.\n",
      "Initialized 'ğŸ‰' with projected e2v weights.\n",
      "Initialized 'ğŸ˜' with projected e2v weights.\n",
      "Initialized 'â­' with projected e2v weights.\n",
      "Initialized 'ğŸš¨' with projected e2v weights.\n",
      "Initialized 'ğŸ’¯' with projected e2v weights.\n",
      "Initialized 'ğŸ™Œ' with projected e2v weights.\n",
      "Initialized 'âš•' with random weights.\n",
      "Initialized 'â€¼' with random weights.\n",
      "Initialized 'ğŸ’š' with projected e2v weights.\n",
      "Initialized 'ğŸ¥°' with random weights.\n",
      "Initialized 'ğŸ™ğŸ»' with projected e2v weights.\n",
      "Initialized 'â—' with projected e2v weights.\n",
      "Initialized 'ğŸ’›' with projected e2v weights.\n",
      "Initialized 'ğŸ¤£' with projected e2v weights.\n",
      "Initialized 'ğŸ’œ' with projected e2v weights.\n",
      "Initialized 'â™€' with random weights.\n",
      "Initialized 'ğŸ©º' with random weights.\n",
      "Initialized 'ğŸ”¹' with projected e2v weights.\n",
      "Initialized 'ğŸ“±' with projected e2v weights.\n",
      "Initialized 'ğŸ“¢' with projected e2v weights.\n",
      "Initialized 'ğŸ‘' with projected e2v weights.\n",
      "Initialized 'ğŸ’»' with projected e2v weights.\n",
      "Initialized 'ğŸ“§' with projected e2v weights.\n",
      "Initialized 'ğŸ“·' with projected e2v weights.\n",
      "Initialized 'â˜€' with random weights.\n",
      "Initialized 'ğŸ¥' with projected e2v weights.\n",
      "Initialized 'ğŸ¤' with projected e2v weights.\n",
      "Initialized 'âœˆ' with random weights.\n",
      "Initialized 'ğŸ‘©' with projected e2v weights.\n",
      "Initialized 'ğŸ¤' with random weights.\n",
      "Initialized 'ğŸ˜‰' with projected e2v weights.\n",
      "Initialized 'ğŸ‘€' with projected e2v weights.\n",
      "Initialized 'ğŸ˜' with projected e2v weights.\n",
      "Initialized 'ğŸŒ' with projected e2v weights.\n",
      "Initialized 'ğŸ“Š' with projected e2v weights.\n",
      "Initialized 'ğŸ¤©' with random weights.\n",
      "Initialized 'ğŸ¤”' with projected e2v weights.\n",
      "Initialized 'ğŸ˜' with projected e2v weights.\n",
      "Initialized 'ğŸ¤—' with projected e2v weights.\n",
      "Initialized 'ğŸ”¸' with projected e2v weights.\n",
      "Initialized 'ğŸ¥³' with random weights.\n",
      "Initialized 'ğŸ§¡' with random weights.\n",
      "Initialized 'ğŸŒˆ' with projected e2v weights.\n",
      "Initialized 'ğŸ’«' with projected e2v weights.\n",
      "Initialized 'ğŸ‘‰ğŸ»' with projected e2v weights.\n",
      "Initialized 'ğŸ“£' with projected e2v weights.\n",
      "Initialized 'ğŸ˜ƒ' with projected e2v weights.\n",
      "Initialized 'ğŸŒ' with projected e2v weights.\n",
      "Initialized 'â¬‡' with random weights.\n",
      "Initialized 'ğŸ§ª' with random weights.\n",
      "Initialized 'âœŒ' with random weights.\n",
      "Initialized 'ğŸ—£' with projected e2v weights.\n",
      "Initialized 'ğŸ’–' with projected e2v weights.\n",
      "Initialized 'ğŸ™‚' with projected e2v weights.\n",
      "Initialized 'â™‚' with random weights.\n",
      "Initialized 'ğŸ“°' with projected e2v weights.\n",
      "Initialized 'ğŸ’¥' with projected e2v weights.\n",
      "Initialized 'ğŸ‘†' with projected e2v weights.\n",
      "Initialized 'ğŸ‘¨' with projected e2v weights.\n",
      "Initialized 'ğŸ“Œ' with projected e2v weights.\n",
      "Initialized 'ğŸ™ğŸ¼' with projected e2v weights.\n",
      "Initialized 'â˜º' with random weights.\n",
      "Initialized 'ğŸ¤‘' with projected e2v weights.\n",
      "Initialized 'ğŸ’¬' with projected e2v weights.\n",
      "Initialized 'ğŸ’°' with projected e2v weights.\n",
      "Initialized 'ğŸ˜‡' with projected e2v weights.\n",
      "Initialized 'ğŸ–¤' with projected e2v weights.\n",
      "Initialized 'ğŸŒº' with projected e2v weights.\n",
      "Initialized 'ğŸ“š' with projected e2v weights.\n",
      "Initialized 'ğŸ¤’' with projected e2v weights.\n",
      "Initialized 'âš¡' with projected e2v weights.\n",
      "Initialized 'ğŸ””' with projected e2v weights.\n",
      "Initialized 'ğŸ¡' with projected e2v weights.\n",
      "Initialized 'ğŸ’¡' with projected e2v weights.\n",
      "Initialized 'ğŸŒ¿' with projected e2v weights.\n",
      "Initialized 'ğŸ˜…' with projected e2v weights.\n",
      "Initialized 'ğŸ¤§' with projected e2v weights.\n",
      "Initialized 'ğŸŒ¸' with projected e2v weights.\n",
      "Initialized 'ğŸ’—' with projected e2v weights.\n",
      "Initialized 'ğŸ™ğŸ½' with projected e2v weights.\n",
      "Initialized 'ğŸ‘ˆ' with projected e2v weights.\n",
      "Initialized 'ğŸ”¬' with projected e2v weights.\n",
      "Initialized 'ğŸ ' with projected e2v weights.\n",
      "Initialized 'ğŸ˜­' with projected e2v weights.\n",
      "Initialized 'ğŸ˜€' with projected e2v weights.\n",
      "Initialized 'ğŸ¥' with projected e2v weights.\n",
      "Initialized 'â¬†' with random weights.\n",
      "Initialized 'ğŸ”·' with projected e2v weights.\n",
      "Initialized 'ğŸ‘¥' with projected e2v weights.\n",
      "Initialized 'ğŸƒ' with projected e2v weights.\n",
      "Initialized 'ğŸ’Š' with projected e2v weights.\n",
      "Initialized 'ğŸ˜˜' with projected e2v weights.\n",
      "Initialized 'â˜ğŸ»' with random weights.\n",
      "Initialized 'ğŸ‘£' with projected e2v weights.\n",
      "Initialized 'â˜' with random weights.\n",
      "Initialized 'ğŸŒ±' with projected e2v weights.\n",
      "Initialized 'ğŸ”´' with projected e2v weights.\n",
      "Initialized 'ğŸ˜„' with projected e2v weights.\n",
      "Initialized 'ğŸ„' with projected e2v weights.\n",
      "Initialized 'â–' with projected e2v weights.\n",
      "Initialized 'ğŸ’Œ' with projected e2v weights.\n",
      "Initialized 'â°' with projected e2v weights.\n",
      "Initialized 'ğŸ“ˆ' with projected e2v weights.\n",
      "Initialized 'ğŸ¨' with projected e2v weights.\n",
      "Initialized 'ğŸ˜±' with projected e2v weights.\n",
      "Initialized 'ğŸš€' with projected e2v weights.\n",
      "Initialized 'ğŸ†' with projected e2v weights.\n",
      "Initialized 'ğŸ”' with projected e2v weights.\n",
      "Initialized 'ğŸ' with projected e2v weights.\n",
      "Initialized 'â˜‘' with random weights.\n",
      "Initialized 'ğŸ“©' with projected e2v weights.\n",
      "Initialized 'ğŸ’”' with projected e2v weights.\n",
      "Initialized 'ğŸ‘‡ğŸ»' with projected e2v weights.\n",
      "Initialized 'ğŸ˜¢' with projected e2v weights.\n",
      "Initialized 'ğŸ—“' with projected e2v weights.\n",
      "Initialized 'ğŸŒ' with projected e2v weights.\n",
      "Initialized 'ğŸ‘‹' with projected e2v weights.\n",
      "Initialized 'ğŸ™ŒğŸ»' with projected e2v weights.\n",
      "Initialized 'ğŸ‡' with projected e2v weights.\n",
      "Initialized 'ğŸ©¸' with random weights.\n",
      "Initialized 'ğŸ¦Ÿ' with random weights.\n",
      "Initialized 'ğŸ’ƒ' with projected e2v weights.\n",
      "Initialized 'ğŸ‘¹' with projected e2v weights.\n",
      "Initialized 'ğŸ‘Œ' with projected e2v weights.\n",
      "Initialized 'ğŸ’§' with projected e2v weights.\n",
      "Initialized 'ğŸš«' with projected e2v weights.\n",
      "Initialized 'âŒ' with projected e2v weights.\n",
      "Initialized 'ğŸ™ŒğŸ½' with projected e2v weights.\n",
      "Initialized 'ğŸ˜”' with projected e2v weights.\n",
      "Initialized 'ğŸ›¡' with projected e2v weights.\n",
      "Initialized 'ğŸ¾' with projected e2v weights.\n",
      "Initialized 'ğŸ™„' with projected e2v weights.\n",
      "Initialized 'ğŸ’ªğŸ»' with projected e2v weights.\n",
      "Initialized 'âœ‰' with random weights.\n",
      "Initialized 'ğŸ' with projected e2v weights.\n",
      "Initialized 'ğŸŠ' with projected e2v weights.\n",
      "Initialized 'âº' with projected e2v weights.\n",
      "Initialized 'ğŸ˜³' with projected e2v weights.\n",
      "Initialized 'ğŸ«¶' with random weights.\n",
      "Initialized 'ğŸ’' with projected e2v weights.\n",
      "Initialized 'ğŸŒ' with projected e2v weights.\n",
      "Initialized 'ğŸ˜Œ' with projected e2v weights.\n",
      "Initialized 'ğŸ“' with projected e2v weights.\n",
      "Initialized 'ğŸˆ' with projected e2v weights.\n",
      "Initialized 'ğŸ§¬' with random weights.\n",
      "Initialized 'ğŸŒ»' with projected e2v weights.\n",
      "Initialized 'ğŸ©' with projected e2v weights.\n",
      "Initialized 'ğŸ•' with projected e2v weights.\n",
      "Initialized 'ğŸ§¼' with random weights.\n",
      "Initialized 'ğŸ¤' with projected e2v weights.\n",
      "Initialized 'ğŸ©¹' with random weights.\n",
      "Initialized 'âœ' with random weights.\n",
      "Initialized 'ğŸŒ¼' with projected e2v weights.\n",
      "Initialized 'â£' with projected e2v weights.\n",
      "Initialized 'â„' with random weights.\n",
      "Initialized 'ğŸ›’' with random weights.\n",
      "Initialized 'ğŸ˜‹' with projected e2v weights.\n",
      "Initialized 'ğŸ‘Š' with projected e2v weights.\n",
      "Initialized 'ğŸ’¼' with projected e2v weights.\n",
      "Initialized 'ğŸ’ªğŸ¼' with projected e2v weights.\n",
      "Initialized 'ğŸ¦·' with random weights.\n",
      "Initialized 'ğŸŒ´' with projected e2v weights.\n",
      "Initialized 'â“' with projected e2v weights.\n",
      "Initialized 'ğŸ²' with projected e2v weights.\n",
      "Initialized 'ğŸ’' with projected e2v weights.\n",
      "Initialized 'ğŸ¶' with projected e2v weights.\n",
      "Initialized 'ğŸ‘‰ğŸ¼' with projected e2v weights.\n"
     ]
    }
   ],
   "source": [
    "new_emoji_tokens = [emoji for emoji in emoji_list if emoji not in tokenizer.get_vocab()]\n",
    "tokenizer.add_tokens(new_emoji_tokens)\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "emoji_projection_layer = torch.nn.Linear(E2V_EMBEDDING_SIZE, model.config.hidden_size)\n",
    "\n",
    "for emoji in new_emoji_tokens:\n",
    "    token_index = tokenizer.convert_tokens_to_ids(emoji)\n",
    "    \n",
    "    if emoji in e2v:\n",
    "        e2v_vector = torch.tensor(e2v[emoji], dtype=torch.float32)\n",
    "        projected_vector = emoji_projection_layer(e2v_vector.unsqueeze(0)).squeeze(0)\n",
    "        embedding_layer.weight.data[token_index] = projected_vector\n",
    "        print(f\"Initialized '{emoji}' with projected e2v weights.\")\n",
    "    else:\n",
    "        embedding_layer.weight.data[token_index] = torch.randn(model.config.hidden_size)\n",
    "        print(f\"Initialized '{emoji}' with random weights.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'â¤' successfully added to the tokenizer with index 30653.\n",
      "'âœ…' successfully added to the tokenizer with index 30654.\n",
      "'ğŸ˜·' successfully added to the tokenizer with index 30655.\n",
      "'ğŸ‘‰' successfully added to the tokenizer with index 30656.\n",
      "'âœ¨' successfully added to the tokenizer with index 30657.\n",
      "'ğŸ’‰' successfully added to the tokenizer with index 30658.\n",
      "'âœ”' successfully added to the tokenizer with index 30659.\n",
      "'â¡' successfully added to the tokenizer with index 30660.\n",
      "'ğŸ™' successfully added to the tokenizer with index 30661.\n",
      "'ğŸ“' successfully added to the tokenizer with index 30662.\n",
      "'ğŸ¦ ' successfully added to the tokenizer with index 30663.\n",
      "'ğŸ‘‡' successfully added to the tokenizer with index 30664.\n",
      "'ğŸ“' successfully added to the tokenizer with index 30665.\n",
      "'âš ' successfully added to the tokenizer with index 30666.\n",
      "'ğŸŒŸ' successfully added to the tokenizer with index 30667.\n",
      "'ğŸ˜‚' successfully added to the tokenizer with index 30668.\n",
      "'ğŸ’™' successfully added to the tokenizer with index 30669.\n",
      "'ğŸ˜Š' successfully added to the tokenizer with index 30670.\n",
      "'ğŸŒ' successfully added to the tokenizer with index 30671.\n",
      "'ğŸ“¸' successfully added to the tokenizer with index 30672.\n",
      "'ğŸ“²' successfully added to the tokenizer with index 30673.\n",
      "'ğŸ’ª' successfully added to the tokenizer with index 30674.\n",
      "'ğŸ’•' successfully added to the tokenizer with index 30675.\n",
      "'â–¶' successfully added to the tokenizer with index 30676.\n",
      "'ğŸ”—' successfully added to the tokenizer with index 30677.\n",
      "'ğŸ”¥' successfully added to the tokenizer with index 30678.\n",
      "'â˜' successfully added to the tokenizer with index 30679.\n",
      "'â„¢' successfully added to the tokenizer with index 1580.\n",
      "'ğŸ‘' successfully added to the tokenizer with index 30680.\n",
      "'ğŸ‰' successfully added to the tokenizer with index 30681.\n",
      "'ğŸ˜' successfully added to the tokenizer with index 30682.\n",
      "'â­' successfully added to the tokenizer with index 30683.\n",
      "'ğŸš¨' successfully added to the tokenizer with index 30684.\n",
      "'ğŸ’¯' successfully added to the tokenizer with index 30685.\n",
      "'ğŸ™Œ' successfully added to the tokenizer with index 30686.\n",
      "'âš•' successfully added to the tokenizer with index 30687.\n",
      "'â€¼' successfully added to the tokenizer with index 30688.\n",
      "'ğŸ’š' successfully added to the tokenizer with index 30689.\n",
      "'ğŸ¥°' successfully added to the tokenizer with index 30690.\n",
      "'ğŸ™ğŸ»' successfully added to the tokenizer with index 30691.\n",
      "'â—' successfully added to the tokenizer with index 30692.\n",
      "'ğŸ’›' successfully added to the tokenizer with index 30693.\n",
      "'â™¥' successfully added to the tokenizer with index 1625.\n",
      "'ğŸ¤£' successfully added to the tokenizer with index 30694.\n",
      "'ğŸ’œ' successfully added to the tokenizer with index 30695.\n",
      "'â™€' successfully added to the tokenizer with index 30696.\n",
      "'ğŸ©º' successfully added to the tokenizer with index 30697.\n",
      "'ğŸ”¹' successfully added to the tokenizer with index 30698.\n",
      "'ğŸ“±' successfully added to the tokenizer with index 30699.\n",
      "'ğŸ“¢' successfully added to the tokenizer with index 30700.\n",
      "'ğŸ‘' successfully added to the tokenizer with index 30701.\n",
      "'ğŸ’»' successfully added to the tokenizer with index 30702.\n",
      "'ğŸ“§' successfully added to the tokenizer with index 30703.\n",
      "'ğŸ“·' successfully added to the tokenizer with index 30704.\n",
      "'â˜€' successfully added to the tokenizer with index 30705.\n",
      "'ğŸ¥' successfully added to the tokenizer with index 30706.\n",
      "'ğŸ¤' successfully added to the tokenizer with index 30707.\n",
      "'â–ª' successfully added to the tokenizer with index 1618.\n",
      "'âœˆ' successfully added to the tokenizer with index 30708.\n",
      "'ğŸ‘©' successfully added to the tokenizer with index 30709.\n",
      "'ğŸ¤' successfully added to the tokenizer with index 30710.\n",
      "'ğŸ˜‰' successfully added to the tokenizer with index 30711.\n",
      "'ğŸ‘€' successfully added to the tokenizer with index 30712.\n",
      "'ğŸ˜' successfully added to the tokenizer with index 30713.\n",
      "'ğŸŒ' successfully added to the tokenizer with index 30714.\n",
      "'ğŸ“Š' successfully added to the tokenizer with index 30715.\n",
      "'ğŸ¤©' successfully added to the tokenizer with index 30716.\n",
      "'ğŸ¤”' successfully added to the tokenizer with index 30717.\n",
      "'ğŸ˜' successfully added to the tokenizer with index 30718.\n",
      "'ğŸ¤—' successfully added to the tokenizer with index 30719.\n",
      "'ğŸ”¸' successfully added to the tokenizer with index 30720.\n",
      "'ğŸ¥³' successfully added to the tokenizer with index 30721.\n",
      "'ğŸ§¡' successfully added to the tokenizer with index 30722.\n",
      "'ğŸŒˆ' successfully added to the tokenizer with index 30723.\n",
      "'ğŸ’«' successfully added to the tokenizer with index 30724.\n",
      "'ğŸ‘‰ğŸ»' successfully added to the tokenizer with index 30725.\n",
      "'ğŸ“£' successfully added to the tokenizer with index 30726.\n",
      "'ğŸ˜ƒ' successfully added to the tokenizer with index 30727.\n",
      "'ğŸŒ' successfully added to the tokenizer with index 30728.\n",
      "'â¬‡' successfully added to the tokenizer with index 30729.\n",
      "'ğŸ§ª' successfully added to the tokenizer with index 30730.\n",
      "'âœŒ' successfully added to the tokenizer with index 30731.\n",
      "'ğŸ—£' successfully added to the tokenizer with index 30732.\n",
      "'ğŸ’–' successfully added to the tokenizer with index 30733.\n",
      "'ğŸ™‚' successfully added to the tokenizer with index 30734.\n",
      "'â™‚' successfully added to the tokenizer with index 30735.\n",
      "'ğŸ“°' successfully added to the tokenizer with index 30736.\n",
      "'ğŸ’¥' successfully added to the tokenizer with index 30737.\n",
      "'â™¦' successfully added to the tokenizer with index 1626.\n",
      "'ğŸ‘†' successfully added to the tokenizer with index 30738.\n",
      "'ğŸ‘¨' successfully added to the tokenizer with index 30739.\n",
      "'Â®' successfully added to the tokenizer with index 1079.\n",
      "'ğŸ“Œ' successfully added to the tokenizer with index 30740.\n",
      "'ğŸ™ğŸ¼' successfully added to the tokenizer with index 30741.\n",
      "'â˜º' successfully added to the tokenizer with index 30742.\n",
      "'ğŸ¤‘' successfully added to the tokenizer with index 30743.\n",
      "'ğŸ’¬' successfully added to the tokenizer with index 30744.\n",
      "'ğŸ’°' successfully added to the tokenizer with index 30745.\n",
      "'ğŸ˜‡' successfully added to the tokenizer with index 30746.\n",
      "'ğŸ–¤' successfully added to the tokenizer with index 30747.\n",
      "'ğŸŒº' successfully added to the tokenizer with index 30748.\n",
      "'ğŸ“š' successfully added to the tokenizer with index 30749.\n",
      "'ğŸ¤’' successfully added to the tokenizer with index 30750.\n",
      "'âš¡' successfully added to the tokenizer with index 30751.\n",
      "'ğŸ””' successfully added to the tokenizer with index 30752.\n",
      "'ğŸ¡' successfully added to the tokenizer with index 30753.\n",
      "'ğŸ’¡' successfully added to the tokenizer with index 30754.\n",
      "'ğŸŒ¿' successfully added to the tokenizer with index 30755.\n",
      "'ğŸ˜…' successfully added to the tokenizer with index 30756.\n",
      "'ğŸ¤§' successfully added to the tokenizer with index 30757.\n",
      "'ğŸŒ¸' successfully added to the tokenizer with index 30758.\n",
      "'ğŸ’—' successfully added to the tokenizer with index 30759.\n",
      "'ğŸ™ğŸ½' successfully added to the tokenizer with index 30760.\n",
      "'ğŸ‘ˆ' successfully added to the tokenizer with index 30761.\n",
      "'ğŸ”¬' successfully added to the tokenizer with index 30762.\n",
      "'ğŸ ' successfully added to the tokenizer with index 30763.\n",
      "'ğŸ˜­' successfully added to the tokenizer with index 30764.\n",
      "'ğŸ˜€' successfully added to the tokenizer with index 30765.\n",
      "'ğŸ¥' successfully added to the tokenizer with index 30766.\n",
      "'â¬†' successfully added to the tokenizer with index 30767.\n",
      "'ğŸ”·' successfully added to the tokenizer with index 30768.\n",
      "'ğŸ‘¥' successfully added to the tokenizer with index 30769.\n",
      "'ğŸƒ' successfully added to the tokenizer with index 30770.\n",
      "'ğŸ’Š' successfully added to the tokenizer with index 30771.\n",
      "'ğŸ˜˜' successfully added to the tokenizer with index 30772.\n",
      "'â˜ğŸ»' successfully added to the tokenizer with index 30773.\n",
      "'ğŸ‘£' successfully added to the tokenizer with index 30774.\n",
      "'â˜' successfully added to the tokenizer with index 30775.\n",
      "'ğŸŒ±' successfully added to the tokenizer with index 30776.\n",
      "'ğŸ”´' successfully added to the tokenizer with index 30777.\n",
      "'ğŸ˜„' successfully added to the tokenizer with index 30778.\n",
      "'ğŸ„' successfully added to the tokenizer with index 30779.\n",
      "'â–' successfully added to the tokenizer with index 30780.\n",
      "'ğŸ’Œ' successfully added to the tokenizer with index 30781.\n",
      "'â°' successfully added to the tokenizer with index 30782.\n",
      "'ğŸ“ˆ' successfully added to the tokenizer with index 30783.\n",
      "'ğŸ¨' successfully added to the tokenizer with index 30784.\n",
      "'ğŸ˜±' successfully added to the tokenizer with index 30785.\n",
      "'ğŸš€' successfully added to the tokenizer with index 30786.\n",
      "'ğŸ†' successfully added to the tokenizer with index 30787.\n",
      "'ğŸ”' successfully added to the tokenizer with index 30788.\n",
      "'ğŸ' successfully added to the tokenizer with index 30789.\n",
      "'â˜‘' successfully added to the tokenizer with index 30790.\n",
      "'ğŸ“©' successfully added to the tokenizer with index 30791.\n",
      "'ğŸ’”' successfully added to the tokenizer with index 30792.\n",
      "'ğŸ‘‡ğŸ»' successfully added to the tokenizer with index 30793.\n",
      "'ğŸ˜¢' successfully added to the tokenizer with index 30794.\n",
      "'ğŸ—“' successfully added to the tokenizer with index 30795.\n",
      "'ğŸŒ' successfully added to the tokenizer with index 30796.\n",
      "'ğŸ‘‹' successfully added to the tokenizer with index 30797.\n",
      "'ğŸ™ŒğŸ»' successfully added to the tokenizer with index 30798.\n",
      "'ğŸ‡' successfully added to the tokenizer with index 30799.\n",
      "'ğŸ©¸' successfully added to the tokenizer with index 30800.\n",
      "'ğŸ¦Ÿ' successfully added to the tokenizer with index 30801.\n",
      "'ğŸ’ƒ' successfully added to the tokenizer with index 30802.\n",
      "'ğŸ‘¹' successfully added to the tokenizer with index 30803.\n",
      "'ğŸ‘Œ' successfully added to the tokenizer with index 30804.\n",
      "'ğŸ’§' successfully added to the tokenizer with index 30805.\n",
      "'ğŸš«' successfully added to the tokenizer with index 30806.\n",
      "'âŒ' successfully added to the tokenizer with index 30807.\n",
      "'ğŸ™ŒğŸ½' successfully added to the tokenizer with index 30808.\n",
      "'ğŸ˜”' successfully added to the tokenizer with index 30809.\n",
      "'ğŸ›¡' successfully added to the tokenizer with index 30810.\n",
      "'ğŸ¾' successfully added to the tokenizer with index 30811.\n",
      "'ğŸ™„' successfully added to the tokenizer with index 30812.\n",
      "'ğŸ’ªğŸ»' successfully added to the tokenizer with index 30813.\n",
      "'âœ‰' successfully added to the tokenizer with index 30814.\n",
      "'ğŸ' successfully added to the tokenizer with index 30815.\n",
      "'ğŸŠ' successfully added to the tokenizer with index 30816.\n",
      "'âº' successfully added to the tokenizer with index 30817.\n",
      "'ğŸ˜³' successfully added to the tokenizer with index 30818.\n",
      "'ğŸ«¶' successfully added to the tokenizer with index 30819.\n",
      "'ğŸ’' successfully added to the tokenizer with index 30820.\n",
      "'ğŸŒ' successfully added to the tokenizer with index 30821.\n",
      "'ğŸ˜Œ' successfully added to the tokenizer with index 30822.\n",
      "'ğŸ“' successfully added to the tokenizer with index 30823.\n",
      "'ğŸˆ' successfully added to the tokenizer with index 30824.\n",
      "'ğŸ§¬' successfully added to the tokenizer with index 30825.\n",
      "'ğŸŒ»' successfully added to the tokenizer with index 30826.\n",
      "'ğŸ©' successfully added to the tokenizer with index 30827.\n",
      "'ğŸ•' successfully added to the tokenizer with index 30828.\n",
      "'ğŸ§¼' successfully added to the tokenizer with index 30829.\n",
      "'ğŸ¤' successfully added to the tokenizer with index 30830.\n",
      "'ğŸ©¹' successfully added to the tokenizer with index 30831.\n",
      "'âœ' successfully added to the tokenizer with index 30832.\n",
      "'ğŸŒ¼' successfully added to the tokenizer with index 30833.\n",
      "'â£' successfully added to the tokenizer with index 30834.\n",
      "'â„' successfully added to the tokenizer with index 30835.\n",
      "'ğŸ›’' successfully added to the tokenizer with index 30836.\n",
      "'ğŸ˜‹' successfully added to the tokenizer with index 30837.\n",
      "'ğŸ‘Š' successfully added to the tokenizer with index 30838.\n",
      "'ğŸ’¼' successfully added to the tokenizer with index 30839.\n",
      "'ğŸ’ªğŸ¼' successfully added to the tokenizer with index 30840.\n",
      "'ğŸ¦·' successfully added to the tokenizer with index 30841.\n",
      "'ğŸŒ´' successfully added to the tokenizer with index 30842.\n",
      "'â“' successfully added to the tokenizer with index 30843.\n",
      "'ğŸ²' successfully added to the tokenizer with index 30844.\n",
      "'ğŸ’' successfully added to the tokenizer with index 30845.\n",
      "'ğŸ¶' successfully added to the tokenizer with index 30846.\n",
      "'ğŸ‘‰ğŸ¼' successfully added to the tokenizer with index 30847.\n"
     ]
    }
   ],
   "source": [
    "for emoji in emoji_list:\n",
    "    token_index = tokenizer.convert_tokens_to_ids(emoji)\n",
    "    if token_index != tokenizer.unk_token_id:\n",
    "        print(f\"'{emoji}' successfully added to the tokenizer with index {token_index}.\")\n",
    "    else:\n",
    "        print(f\"'{emoji}' was not added to the tokenizer.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for 'â¤': tensor([-1.9318,  1.3915,  0.2706,  0.6012, -1.2936])\n",
      "Embedding for 'âœ…': tensor([ 0.0045, -0.0347,  0.0493, -0.0238, -0.0845])\n",
      "Embedding for 'ğŸ˜·': tensor([ 0.0257, -0.0700,  0.0110,  0.0366, -0.0962])\n",
      "Embedding for 'ğŸ‘‰': tensor([ 0.0352, -0.0107,  0.0786, -0.0365, -0.0146])\n",
      "Embedding for 'âœ¨': tensor([ 0.0493, -0.0641,  0.0667,  0.0196, -0.0253])\n",
      "Embedding for 'ğŸ’‰': tensor([ 0.0545, -0.0260,  0.0555,  0.0024, -0.0931])\n",
      "Embedding for 'âœ”': tensor([ 0.5333, -1.5993,  1.1099, -0.5623,  0.2066])\n",
      "Embedding for 'â¡': tensor([ 1.9998,  0.5251, -0.9919,  0.8025, -0.9525])\n",
      "Embedding for 'ğŸ™': tensor([ 0.0116, -0.0413,  0.0525, -0.0464, -0.1010])\n",
      "Embedding for 'ğŸ“': tensor([ 0.0313, -0.0385,  0.0822, -0.0313, -0.0587])\n",
      "Embedding for 'ğŸ¦ ': tensor([-0.1094,  0.3395, -0.6321, -1.3158, -0.6772])\n",
      "Embedding for 'ğŸ‘‡': tensor([ 0.0509, -0.0328,  0.0651, -0.0666,  0.0037])\n",
      "Embedding for 'ğŸ“': tensor([ 0.0410, -0.0845,  0.0979, -0.0110, -0.0151])\n",
      "Embedding for 'âš ': tensor([-0.8477, -0.6070, -0.0281, -1.1280,  0.8505])\n",
      "Embedding for 'ğŸŒŸ': tensor([ 0.0553, -0.0086,  0.0800,  0.0534,  0.0007])\n",
      "Embedding for 'ğŸ˜‚': tensor([ 0.0352, -0.0382,  0.0640,  0.0178, -0.0442])\n",
      "Embedding for 'ğŸ’™': tensor([ 0.0190, -0.0560,  0.0422, -0.0029, -0.0738])\n",
      "Embedding for 'ğŸ˜Š': tensor([ 0.0769, -0.0614,  0.0537, -0.0355, -0.0721])\n",
      "Embedding for 'ğŸŒ': tensor([-0.0167,  0.0190,  0.0849,  0.0103, -0.0454])\n",
      "Embedding for 'ğŸ“¸': tensor([ 0.0021, -0.0405,  0.0594, -0.0855, -0.0556])\n",
      "Embedding for 'ğŸ“²': tensor([ 0.0621, -0.0777,  0.1118,  0.0026, -0.0250])\n",
      "Embedding for 'ğŸ’ª': tensor([-0.0010, -0.0530,  0.0518, -0.0201, -0.0473])\n",
      "Embedding for 'ğŸ’•': tensor([ 0.0209,  0.0155,  0.0743,  0.0123, -0.0105])\n",
      "Embedding for 'â–¶': tensor([ 0.0688,  1.0788,  0.6477, -1.5114,  0.6355])\n",
      "Embedding for 'ğŸ”—': tensor([ 0.0513, -0.0251,  0.0821, -0.0567, -0.0998])\n",
      "Embedding for 'ğŸ”¥': tensor([-0.0183, -0.0737,  0.1274, -0.0199, -0.0602])\n",
      "Embedding for 'â˜': tensor([ 0.4987,  0.5597,  1.7548, -0.2312,  1.7440])\n",
      "Embedding for 'â„¢': tensor([-0.0218, -0.0719, -0.0202, -0.0691, -0.0253])\n",
      "Embedding for 'ğŸ‘': tensor([ 0.0008, -0.0019,  0.1101, -0.0617, -0.0527])\n",
      "Embedding for 'ğŸ‰': tensor([ 0.0274, -0.0664,  0.0641,  0.0193, -0.0422])\n",
      "Embedding for 'ğŸ˜': tensor([ 0.0326, -0.0504,  0.0670,  0.0433, -0.0646])\n",
      "Embedding for 'â­': tensor([ 0.0224, -0.0819,  0.0369,  0.0127, -0.0262])\n",
      "Embedding for 'ğŸš¨': tensor([ 0.0663, -0.1020,  0.1387, -0.0112, -0.0533])\n",
      "Embedding for 'ğŸ’¯': tensor([ 0.0308,  0.0066,  0.0560,  0.0028, -0.0650])\n",
      "Embedding for 'ğŸ™Œ': tensor([-0.0031, -0.0263,  0.0770, -0.0222, -0.0273])\n",
      "Embedding for 'âš•': tensor([-0.8166,  1.1281,  0.7247,  0.2955,  1.3979])\n",
      "Embedding for 'â€¼': tensor([ 0.3278,  0.7076,  0.2834,  1.0696, -1.1884])\n",
      "Embedding for 'ğŸ’š': tensor([-0.0248, -0.0728,  0.0187,  0.0369, -0.0542])\n",
      "Embedding for 'ğŸ¥°': tensor([-0.2403,  1.2102,  0.2840, -0.7947,  0.1772])\n",
      "Embedding for 'ğŸ™ğŸ»': tensor([ 0.0120, -0.0480,  0.0600, -0.0201, -0.0571])\n",
      "Embedding for 'â—': tensor([-0.0072, -0.0159,  0.0741, -0.0275, -0.0499])\n",
      "Embedding for 'ğŸ’›': tensor([-0.0024, -0.0690,  0.0604, -0.0152, -0.0555])\n",
      "Embedding for 'â™¥': tensor([-0.0117, -0.0445,  0.0131, -0.0619,  0.0259])\n",
      "Embedding for 'ğŸ¤£': tensor([ 0.0212, -0.0314,  0.0444, -0.0203, -0.0854])\n",
      "Embedding for 'ğŸ’œ': tensor([-0.0032, -0.0660,  0.0559,  0.0228, -0.0613])\n",
      "Embedding for 'â™€': tensor([ 0.0979,  0.8184,  1.7743, -0.0101,  0.0144])\n",
      "Embedding for 'ğŸ©º': tensor([ 0.8314, -1.0210, -0.1560,  0.0430, -1.4851])\n",
      "Embedding for 'ğŸ”¹': tensor([ 0.0557, -0.0483, -0.0009, -0.0299, -0.0193])\n",
      "Embedding for 'ğŸ“±': tensor([-0.0011, -0.0738,  0.0720, -0.0298, -0.0319])\n",
      "Embedding for 'ğŸ“¢': tensor([ 0.0421, -0.0364,  0.0456, -0.0434, -0.0626])\n",
      "Embedding for 'ğŸ‘': tensor([ 0.0137, -0.0321,  0.0934, -0.0292, -0.0428])\n",
      "Embedding for 'ğŸ’»': tensor([ 0.0321, -0.0247,  0.0427, -0.0143, -0.0558])\n",
      "Embedding for 'ğŸ“§': tensor([-0.0021, -0.0620,  0.0336, -0.0121, -0.0435])\n",
      "Embedding for 'ğŸ“·': tensor([ 0.0704, -0.0880,  0.0618, -0.0471, -0.0592])\n",
      "Embedding for 'â˜€': tensor([-0.2476,  0.3341,  0.9238,  0.3129,  1.6306])\n",
      "Embedding for 'ğŸ¥': tensor([ 0.0358, -0.0471,  0.0332, -0.0064, -0.0507])\n",
      "Embedding for 'ğŸ¤': tensor([ 0.0532, -0.0490,  0.0940, -0.0632, -0.0844])\n",
      "Embedding for 'â–ª': tensor([-0.0063, -0.0593, -0.0079, -0.0759,  0.0023])\n",
      "Embedding for 'âœˆ': tensor([ 0.6824,  0.0941,  0.0207,  1.1924, -1.8383])\n",
      "Embedding for 'ğŸ‘©': tensor([ 0.0060, -0.0833,  0.0792,  0.0309, -0.0522])\n",
      "Embedding for 'ğŸ¤': tensor([-0.1434,  1.6149,  2.1626, -2.0504, -0.1728])\n",
      "Embedding for 'ğŸ˜‰': tensor([ 0.0605, -0.0385,  0.0602, -0.0409, -0.0615])\n",
      "Embedding for 'ğŸ‘€': tensor([ 0.0529, -0.0491,  0.0671, -0.0466, -0.0218])\n",
      "Embedding for 'ğŸ˜': tensor([ 0.0553, -0.0503,  0.0318, -0.0392, -0.0905])\n",
      "Embedding for 'ğŸŒ': tensor([ 0.0030,  0.0102,  0.0834,  0.0167, -0.0517])\n",
      "Embedding for 'ğŸ“Š': tensor([ 0.0163,  0.0105,  0.0332, -0.0355, -0.0583])\n",
      "Embedding for 'ğŸ¤©': tensor([-0.9006,  0.9836,  0.3745, -0.0570, -0.4749])\n",
      "Embedding for 'ğŸ¤”': tensor([-0.0255, -0.0774,  0.1005, -0.0198, -0.0217])\n",
      "Embedding for 'ğŸ˜': tensor([ 0.0634, -0.0608,  0.0356,  0.0288, -0.1050])\n",
      "Embedding for 'ğŸ¤—': tensor([ 0.0630, -0.0454,  0.0654, -0.0014, -0.0535])\n",
      "Embedding for 'ğŸ”¸': tensor([ 0.0484, -0.0574,  0.0332,  0.0160, -0.0340])\n",
      "Embedding for 'ğŸ¥³': tensor([ 0.2512, -2.2589,  0.7573,  0.6954,  0.7968])\n",
      "Embedding for 'ğŸ§¡': tensor([-1.0201,  0.8686,  1.7717,  0.9041, -2.4715])\n",
      "Embedding for 'ğŸŒˆ': tensor([-0.0050, -0.0304,  0.0416,  0.0109, -0.0066])\n",
      "Embedding for 'ğŸ’«': tensor([ 0.0078, -0.0934,  0.0401,  0.0131, -0.0536])\n",
      "Embedding for 'ğŸ‘‰ğŸ»': tensor([ 0.0247, -0.0497,  0.0660,  0.0524, -0.0148])\n",
      "Embedding for 'ğŸ“£': tensor([ 0.0271, -0.0619,  0.1014, -0.0537, -0.0673])\n",
      "Embedding for 'ğŸ˜ƒ': tensor([ 0.0524, -0.0715,  0.0450, -0.0219, -0.0744])\n",
      "Embedding for 'ğŸŒ': tensor([ 0.0056,  0.0083,  0.0686,  0.0138, -0.0504])\n",
      "Embedding for 'â¬‡': tensor([ 1.2737, -0.4162,  0.9688,  0.2984,  0.6347])\n",
      "Embedding for 'ğŸ§ª': tensor([-2.0195, -0.2475,  1.2444, -0.2848, -0.2998])\n",
      "Embedding for 'âœŒ': tensor([ 0.1540, -0.5663, -0.0106, -0.4142,  1.3155])\n",
      "Embedding for 'ğŸ—£': tensor([ 0.0421,  0.0214,  0.1123, -0.0387, -0.0627])\n",
      "Embedding for 'ğŸ’–': tensor([ 0.0202, -0.0668,  0.0618,  0.0506, -0.0444])\n",
      "Embedding for 'ğŸ™‚': tensor([ 0.0443, -0.0519,  0.0948, -0.0033, -0.0882])\n",
      "Embedding for 'â™‚': tensor([-1.9433,  0.0162,  1.1709,  0.0031,  0.9687])\n",
      "Embedding for 'ğŸ“°': tensor([ 0.1029, -0.0056,  0.0993, -0.1000, -0.0420])\n",
      "Embedding for 'ğŸ’¥': tensor([ 0.0351, -0.0566,  0.0651, -0.0165, -0.0555])\n",
      "Embedding for 'â™¦': tensor([-0.0016, -0.0744,  0.0105, -0.0599,  0.0529])\n",
      "Embedding for 'ğŸ‘†': tensor([ 0.0556, -0.0246,  0.0872, -0.0971, -0.0096])\n",
      "Embedding for 'ğŸ‘¨': tensor([-0.0163, -0.1150,  0.0315,  0.0121, -0.0621])\n",
      "Embedding for 'Â®': tensor([ 0.0381, -0.1138,  0.0307, -0.0183, -0.0051])\n",
      "Embedding for 'ğŸ“Œ': tensor([-0.0132, -0.0208,  0.1090, -0.0427, -0.0823])\n",
      "Embedding for 'ğŸ™ğŸ¼': tensor([ 0.0315, -0.0610,  0.0391, -0.0410, -0.0812])\n",
      "Embedding for 'â˜º': tensor([-1.7469,  2.1547, -1.0532, -0.6110, -0.6209])\n",
      "Embedding for 'ğŸ¤‘': tensor([ 0.0490, -0.0221,  0.1030, -0.0206, -0.1293])\n",
      "Embedding for 'ğŸ’¬': tensor([ 0.0301, -0.0311,  0.0777,  0.0153, -0.0322])\n",
      "Embedding for 'ğŸ’°': tensor([ 0.0437, -0.0039,  0.0686, -0.0520, -0.0816])\n",
      "Embedding for 'ğŸ˜‡': tensor([ 0.0098, -0.0539,  0.0814, -0.0674, -0.0891])\n",
      "Embedding for 'ğŸ–¤': tensor([ 0.0179, -0.0524,  0.0543,  0.0468, -0.0806])\n",
      "Embedding for 'ğŸŒº': tensor([ 0.0612, -0.0741,  0.0915,  0.0407, -0.0995])\n",
      "Embedding for 'ğŸ“š': tensor([ 0.1112,  0.0107,  0.0767, -0.0057, -0.0179])\n",
      "Embedding for 'ğŸ¤’': tensor([ 0.0440, -0.0888,  0.0178, -0.0358, -0.1228])\n",
      "Embedding for 'âš¡': tensor([ 0.0044, -0.0162,  0.0950, -0.0249, -0.0316])\n",
      "Embedding for 'ğŸ””': tensor([ 0.0153, -0.0916,  0.0949, -0.0262, -0.0227])\n",
      "Embedding for 'ğŸ¡': tensor([ 0.0044, -0.0874,  0.0872, -0.0171, -0.0598])\n",
      "Embedding for 'ğŸ’¡': tensor([ 0.0377, -0.0183,  0.0967, -0.0391, -0.0533])\n",
      "Embedding for 'ğŸŒ¿': tensor([ 0.0588, -0.0215,  0.0699,  0.0471, -0.0650])\n",
      "Embedding for 'ğŸ˜…': tensor([ 0.0608,  0.0030,  0.0524, -0.0798, -0.1012])\n",
      "Embedding for 'ğŸ¤§': tensor([ 0.0506, -0.0814,  0.0237, -0.0160, -0.0901])\n",
      "Embedding for 'ğŸŒ¸': tensor([ 0.0469, -0.0877,  0.0700,  0.0323, -0.0381])\n",
      "Embedding for 'ğŸ’—': tensor([ 0.0219, -0.0580,  0.0707,  0.0417, -0.0530])\n",
      "Embedding for 'ğŸ™ğŸ½': tensor([-0.0167, -0.0547,  0.0615, -0.0097, -0.0752])\n",
      "Embedding for 'ğŸ‘ˆ': tensor([ 0.0492, -0.0257,  0.0717, -0.0547, -0.0131])\n",
      "Embedding for 'ğŸ”¬': tensor([ 0.0606, -0.0400,  0.0573,  0.0196, -0.1015])\n",
      "Embedding for 'ğŸ ': tensor([-0.0192, -0.0704,  0.0799, -0.0136, -0.0179])\n",
      "Embedding for 'ğŸ˜­': tensor([ 0.0420, -0.0490,  0.0503,  0.0396, -0.0811])\n",
      "Embedding for 'ğŸ˜€': tensor([ 0.0855, -0.0540,  0.0559, -0.0305, -0.0719])\n",
      "Embedding for 'ğŸ¥': tensor([ 0.0276, -0.0916,  0.0769,  0.0033, -0.0840])\n",
      "Embedding for 'â¬†': tensor([-1.3233, -0.1431,  0.1394,  0.9021, -0.0554])\n",
      "Embedding for 'ğŸ”·': tensor([ 0.0321, -0.0328, -0.0194, -0.0187, -0.0109])\n",
      "Embedding for 'ğŸ‘¥': tensor([ 0.0284, -0.0579,  0.0632, -0.0011, -0.0904])\n",
      "Embedding for 'ğŸƒ': tensor([ 0.0019, -0.0396,  0.0506,  0.0008, -0.0226])\n",
      "Embedding for 'ğŸ’Š': tensor([ 0.0547, -0.0515,  0.0132, -0.0038, -0.0927])\n",
      "Embedding for 'ğŸ˜˜': tensor([ 0.0353, -0.0647,  0.0588,  0.0044, -0.1022])\n",
      "Embedding for 'â˜ğŸ»': tensor([ 0.2391,  1.0936, -0.8379,  0.1212,  0.6704])\n",
      "Embedding for 'ğŸ‘£': tensor([ 0.0297, -0.0035,  0.0328, -0.0602, -0.0466])\n",
      "Embedding for 'â˜': tensor([-1.1441, -0.3318, -0.0120,  0.7647,  0.0863])\n",
      "Embedding for 'ğŸŒ±': tensor([ 0.0852, -0.0535,  0.0481,  0.0029, -0.0435])\n",
      "Embedding for 'ğŸ”´': tensor([ 0.0597, -0.0386,  0.0395, -0.0631, -0.0322])\n",
      "Embedding for 'ğŸ˜„': tensor([ 0.0855, -0.0537,  0.0536, -0.0319, -0.0636])\n",
      "Embedding for 'ğŸ„': tensor([ 0.0020, -0.0633,  0.0627,  0.0082, -0.0201])\n",
      "Embedding for 'â–': tensor([-0.0077, -0.0086,  0.0846, -0.0384, -0.0132])\n",
      "Embedding for 'ğŸ’Œ': tensor([-0.0122, -0.0462,  0.0621,  0.0464, -0.0654])\n",
      "Embedding for 'â°': tensor([ 0.0299, -0.0627,  0.0574, -0.0180, -0.0570])\n",
      "Embedding for 'ğŸ“ˆ': tensor([ 0.0225,  0.0220,  0.0652, -0.0656, -0.0567])\n",
      "Embedding for 'ğŸ¨': tensor([ 0.0741,  0.0146,  0.1150,  0.0386, -0.0529])\n",
      "Embedding for 'ğŸ˜±': tensor([ 0.0268, -0.0538,  0.0852,  0.0277, -0.0181])\n",
      "Embedding for 'ğŸš€': tensor([-0.0228, -0.0831,  0.0826, -0.0315, -0.0110])\n",
      "Embedding for 'ğŸ†': tensor([ 0.0264, -0.0065,  0.1083, -0.0370, -0.0165])\n",
      "Embedding for 'ğŸ”': tensor([-0.0350, -0.0086,  0.0700, -0.0501, -0.0960])\n",
      "Embedding for 'ğŸ': tensor([ 0.0265, -0.0256,  0.0628, -0.0200, -0.0886])\n",
      "Embedding for 'â˜‘': tensor([-0.3540,  0.3113, -1.0724,  2.1999,  0.7658])\n",
      "Embedding for 'ğŸ“©': tensor([-0.0293, -0.0521,  0.0267, -0.0494, -0.0388])\n",
      "Embedding for 'ğŸ’”': tensor([-0.0168, -0.0605,  0.0475,  0.0167, -0.0338])\n",
      "Embedding for 'ğŸ‘‡ğŸ»': tensor([ 0.0433, -0.0511,  0.0284,  0.0127, -0.0196])\n",
      "Embedding for 'ğŸ˜¢': tensor([ 0.0190, -0.0255,  0.0702,  0.0174, -0.0491])\n",
      "Embedding for 'ğŸ—“': tensor([ 0.0323, -0.0090,  0.0952, -0.0339, -0.0646])\n",
      "Embedding for 'ğŸŒ': tensor([ 0.0642, -0.0901,  0.0681,  0.0403, -0.0941])\n",
      "Embedding for 'ğŸ‘‹': tensor([ 0.0569, -0.0532,  0.0707, -0.0208, -0.0876])\n",
      "Embedding for 'ğŸ™ŒğŸ»': tensor([ 0.0395, -0.0380,  0.0470, -0.0115, -0.0845])\n",
      "Embedding for 'ğŸ‡': tensor([-0.0048, -0.1198,  0.0862, -0.0156, -0.0268])\n",
      "Embedding for 'ğŸ©¸': tensor([-0.3721,  1.3544,  0.0501,  0.5987,  0.8912])\n",
      "Embedding for 'ğŸ¦Ÿ': tensor([-0.0665, -0.8831, -0.2280,  0.8273, -0.5780])\n",
      "Embedding for 'ğŸ’ƒ': tensor([-0.0059, -0.0529,  0.0979,  0.0592, -0.0363])\n",
      "Embedding for 'ğŸ‘¹': tensor([-0.0090, -0.0733,  0.0508,  0.0180, -0.0325])\n",
      "Embedding for 'ğŸ‘Œ': tensor([ 0.0275, -0.0514,  0.0464,  0.0166, -0.0474])\n",
      "Embedding for 'ğŸ’§': tensor([ 0.0395, -0.0556,  0.0526, -0.0109, -0.0791])\n",
      "Embedding for 'ğŸš«': tensor([ 0.0034, -0.0267,  0.0716, -0.0471, -0.0411])\n",
      "Embedding for 'âŒ': tensor([ 0.0146, -0.0086,  0.0342, -0.0598, -0.0439])\n",
      "Embedding for 'ğŸ™ŒğŸ½': tensor([-0.0017, -0.0435,  0.0736, -0.0074, -0.1045])\n",
      "Embedding for 'ğŸ˜”': tensor([ 0.0069, -0.0285,  0.0431,  0.0234, -0.0441])\n",
      "Embedding for 'ğŸ›¡': tensor([ 0.0016, -0.1194,  0.0813, -0.0580, -0.0558])\n",
      "Embedding for 'ğŸ¾': tensor([ 0.0215, -0.0304,  0.0636, -0.0792, -0.0531])\n",
      "Embedding for 'ğŸ™„': tensor([ 0.0706, -0.0572,  0.0934, -0.0662, -0.0776])\n",
      "Embedding for 'ğŸ’ªğŸ»': tensor([ 0.0341, -0.0307,  0.0828,  0.0478, -0.0028])\n",
      "Embedding for 'âœ‰': tensor([ 0.3479, -0.1656,  0.7037,  1.0954,  1.8784])\n",
      "Embedding for 'ğŸ': tensor([ 0.0969, -0.0689,  0.0709,  0.0067, -0.0309])\n",
      "Embedding for 'ğŸŠ': tensor([ 0.0329, -0.0192,  0.0800,  0.0117, -0.0195])\n",
      "Embedding for 'âº': tensor([ 0.0272, -0.0450,  0.0821, -0.0552, -0.0880])\n",
      "Embedding for 'ğŸ˜³': tensor([ 0.0398, -0.0398,  0.0439, -0.0529, -0.0602])\n",
      "Embedding for 'ğŸ«¶': tensor([ 0.7665, -0.0791, -0.9592, -1.6106, -0.8252])\n",
      "Embedding for 'ğŸ’': tensor([ 0.0475, -0.0453,  0.0849, -0.0488, -0.0185])\n",
      "Embedding for 'ğŸŒ': tensor([ 0.0082, -0.0027,  0.0815,  0.0066, -0.0722])\n",
      "Embedding for 'ğŸ˜Œ': tensor([ 0.0212,  0.0043,  0.0368, -0.0745, -0.0536])\n",
      "Embedding for 'ğŸ“': tensor([-1.9278e-02,  3.3757e-03,  1.9959e-02, -8.1602e-05, -3.5893e-02])\n",
      "Embedding for 'ğŸˆ': tensor([ 0.0047, -0.0970,  0.0560, -0.0045, -0.0942])\n",
      "Embedding for 'ğŸ§¬': tensor([-0.5854, -0.9065,  0.3900, -0.1350,  1.6493])\n",
      "Embedding for 'ğŸŒ»': tensor([ 0.0523, -0.0582,  0.0300,  0.0299, -0.1043])\n",
      "Embedding for 'ğŸ©': tensor([ 0.0302, -0.0844,  0.0508,  0.0073, -0.0794])\n",
      "Embedding for 'ğŸ•': tensor([ 0.0275, -0.0535,  0.0837, -0.0246, -0.0180])\n",
      "Embedding for 'ğŸ§¼': tensor([0.2764, 0.8370, 0.0683, 2.0743, 0.2773])\n",
      "Embedding for 'ğŸ¤': tensor([ 0.0584,  0.0433,  0.0746, -0.0734, -0.0542])\n",
      "Embedding for 'ğŸ©¹': tensor([-1.3537,  0.4762,  0.0539,  0.3444,  0.0279])\n",
      "Embedding for 'âœ': tensor([-0.2823,  0.2588,  0.0724, -0.4842,  0.6607])\n",
      "Embedding for 'ğŸŒ¼': tensor([ 0.0395, -0.1022,  0.0326,  0.0282, -0.0564])\n",
      "Embedding for 'â£': tensor([-0.0200, -0.0594,  0.0580, -0.0236, -0.0924])\n",
      "Embedding for 'â„': tensor([-2.3383,  0.7211,  2.4191,  1.9598, -0.2948])\n",
      "Embedding for 'ğŸ›’': tensor([0.9632, 1.3089, 0.0896, 0.2567, 0.4606])\n",
      "Embedding for 'ğŸ˜‹': tensor([ 0.0378, -0.0288,  0.0373,  0.0169, -0.0072])\n",
      "Embedding for 'ğŸ‘Š': tensor([ 0.0319, -0.0289,  0.0744, -0.0986, -0.1122])\n",
      "Embedding for 'ğŸ’¼': tensor([ 0.0264, -0.0582,  0.0388, -0.0376, -0.0439])\n",
      "Embedding for 'ğŸ’ªğŸ¼': tensor([ 0.0858, -0.0125,  0.0442, -0.0332, -0.0337])\n",
      "Embedding for 'ğŸ¦·': tensor([ 0.2958, -0.3088,  0.5235, -0.3079,  0.2745])\n",
      "Embedding for 'ğŸŒ´': tensor([ 0.0633, -0.0879,  0.0752,  0.0212, -0.1279])\n",
      "Embedding for 'â“': tensor([-0.0060, -0.0511,  0.1047, -0.0503, -0.0046])\n",
      "Embedding for 'ğŸ²': tensor([ 0.0170, -0.0457,  0.0615, -0.0054, -0.0247])\n",
      "Embedding for 'ğŸ’': tensor([ 0.0484, -0.0224,  0.0668, -0.0248, -0.0520])\n",
      "Embedding for 'ğŸ¶': tensor([ 0.0430, -0.0275,  0.0692,  0.0242, -0.0439])\n",
      "Embedding for 'ğŸ‘‰ğŸ¼': tensor([ 0.0280, -0.0578,  0.0284,  0.0407, -0.0139])\n"
     ]
    }
   ],
   "source": [
    "for emoji in emoji_list:\n",
    "    token_index = tokenizer.convert_tokens_to_ids(emoji)\n",
    "    embedding_vector = embedding_layer.weight.data[token_index]\n",
    "    print(f\"Embedding for '{emoji}': {embedding_vector[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved to ./expanded_vocab_bert\n"
     ]
    }
   ],
   "source": [
    "model_save_path = \"./expanded_vocab_bert\"\n",
    "\n",
    "model.save_pretrained(model_save_path)\n",
    "\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "\n",
    "print(f\"Model and tokenizer saved to {model_save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "newTokenizer = BertTokenizer.from_pretrained(model_save_path)\n",
    "newModel = BertModel.from_pretrained(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token ID for slang 'gratz': 30651\n",
      "Token ID for emoji 'âœ…': 30654\n",
      "Slang 'gratz' is in the vocabulary.\n",
      "Emoji 'âœ…' is in the vocabulary.\n"
     ]
    }
   ],
   "source": [
    "test_slang = \"gratz\"\n",
    "test_emoji = \"âœ…\"\n",
    "\n",
    "slang_id = tokenizer.convert_tokens_to_ids(test_slang)\n",
    "emoji_id = tokenizer.convert_tokens_to_ids(test_emoji)\n",
    "\n",
    "print(f\"Token ID for slang '{test_slang}': {slang_id}\")\n",
    "print(f\"Token ID for emoji '{test_emoji}': {emoji_id}\")\n",
    "\n",
    "if slang_id == tokenizer.unk_token_id:\n",
    "    print(f\"Slang '{test_slang}' is not in the vocabulary.\")\n",
    "else:\n",
    "    print(f\"Slang '{test_slang}' is in the vocabulary.\")\n",
    "\n",
    "if emoji_id == tokenizer.unk_token_id:\n",
    "    print(f\"Emoji '{test_emoji}' is not in the vocabulary.\")\n",
    "else:\n",
    "    print(f\"Emoji '{test_emoji}' is in the vocabulary.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for slang 'gratz': tensor([ 3.0528e-02,  2.0413e-01, -1.8689e-01, -9.5478e-02, -1.3664e-01,\n",
      "        -3.6737e-02, -9.7823e-02, -3.1699e-02,  1.4831e-01,  1.4878e-01,\n",
      "         3.5912e-01,  1.9500e-01, -2.4533e-01, -1.5895e-01, -5.7964e-02,\n",
      "         1.8909e-01,  1.9251e-01,  1.6659e-01,  1.7418e-01,  1.5912e-01,\n",
      "         7.7693e-02,  3.1886e-02, -3.2958e-01,  2.7532e-01, -2.1682e-01,\n",
      "        -4.7799e-01, -8.9799e-02, -1.4757e-02,  2.9868e-01, -1.9759e-01,\n",
      "         3.6164e-02,  2.4430e-01, -1.3531e-02,  3.5472e-01, -2.6867e-01,\n",
      "         2.9537e-02, -1.0596e-01,  1.7264e-01, -1.2466e-01,  6.0011e-03,\n",
      "         6.5716e-02,  1.0858e-01, -4.1726e-01,  3.5357e-01, -2.0372e-01,\n",
      "        -2.3939e-01, -7.8870e-02,  1.0573e-01,  4.7009e-01,  2.1477e-04,\n",
      "         2.4618e-01,  3.2215e-01,  9.5944e-02, -2.0055e-01, -9.6634e-02,\n",
      "         1.9768e-01, -4.2679e-02,  1.2662e-01,  1.7296e-01,  3.2968e-01,\n",
      "         1.2838e-01, -2.0800e-01,  2.9591e-02,  1.6847e-01, -1.1582e-01,\n",
      "        -2.6298e-03, -1.7753e-01,  3.5082e-02,  1.0427e-01, -1.7329e-01,\n",
      "         6.8475e-02, -1.9248e-01,  3.2386e-02, -1.9960e-02, -2.1087e-02,\n",
      "        -1.0693e-01, -3.0878e-01, -1.0702e-01, -3.7408e-01,  4.1677e-02,\n",
      "        -2.6308e-01,  5.2092e-02, -6.9458e-02,  1.2240e-01,  1.6968e-01,\n",
      "         5.7984e-02,  2.7350e-03, -3.8367e-02,  4.8515e-02,  1.5549e-03,\n",
      "         6.2710e-02, -9.9557e-02,  5.9539e-01,  2.7243e-01,  9.1269e-02,\n",
      "         2.4121e-01, -1.0579e-01,  5.2480e-02, -6.9857e-01,  1.1962e-01,\n",
      "         2.8465e-01,  1.8610e-02,  7.3830e-02,  1.2400e-01,  6.6047e-01,\n",
      "        -6.2370e-02,  8.2281e-02,  1.3659e-01,  2.8548e-01, -6.0747e-02,\n",
      "         1.8291e-01,  1.6496e-01, -5.8779e-02,  8.0213e-02, -1.7325e-01,\n",
      "         3.0275e-01, -3.3551e-02,  4.5937e-02, -3.0771e-01,  2.6358e-02,\n",
      "         1.1368e-01,  2.7364e-01, -4.1993e-01, -1.5530e-01, -4.5879e-02,\n",
      "         1.0147e-01,  3.0857e-02, -1.9773e-01,  1.5425e-01, -1.1519e-01,\n",
      "         5.0350e-03, -7.2388e-02,  4.3568e-02,  3.1995e-01, -1.9877e-01,\n",
      "        -3.0926e-01,  4.0674e-01, -1.0798e-01,  7.7861e-03,  9.0011e-02,\n",
      "        -2.3719e-02, -9.0739e-02, -1.2853e-01, -3.5944e-01,  1.6269e-01,\n",
      "         2.0523e-01, -1.6818e-01, -2.8645e-01, -1.0384e-01,  4.1034e-01,\n",
      "         8.8872e-02, -9.4090e-02,  2.9631e-02,  1.5599e-02,  2.3157e-01,\n",
      "        -6.4083e-02, -1.8769e-01,  6.3191e-03, -5.2518e-01, -3.0143e-01,\n",
      "         3.7538e-01,  1.1524e-02, -4.4642e-01, -4.2857e-02,  3.5754e-03,\n",
      "        -1.8112e-01,  9.1092e-02,  1.7280e-01,  3.3201e-01,  2.6207e-01,\n",
      "        -1.3265e-01, -8.3306e-02,  1.0393e-01, -4.1482e-01, -1.4168e-02,\n",
      "        -4.2199e-03,  1.3794e-01, -2.1622e-01,  3.3875e-01, -3.2851e-01,\n",
      "        -2.0783e-02, -5.6446e-02,  8.4802e-02,  9.6582e-02,  3.4435e-01,\n",
      "        -7.7516e-02,  3.6177e-01, -4.7067e-02, -8.1064e-02,  1.5787e-01,\n",
      "         4.3328e-02, -2.8939e-01,  8.2698e-02, -1.9049e-01, -7.4710e-03,\n",
      "         6.0090e-02, -4.0025e-02,  1.5877e-01,  2.1338e-01, -3.5164e-01,\n",
      "        -2.3406e-01,  8.7519e-02,  8.3414e-02,  4.0236e-01,  1.2226e-01,\n",
      "         1.5221e-01,  9.2521e-03, -8.6665e-02, -1.4924e-01,  4.4976e-02,\n",
      "        -8.7109e-02, -4.7205e-02,  7.5780e-02,  2.4892e-01,  3.2225e-01,\n",
      "         1.6296e-02,  8.3574e-02,  2.0167e-02, -4.3013e-01,  2.9556e-01,\n",
      "        -4.0992e-01, -8.2385e-02,  2.5630e-01, -8.9905e-02, -1.3542e-01,\n",
      "         3.2430e-01, -2.2752e-02, -4.2887e-02, -2.5694e-01, -1.5776e-01,\n",
      "        -2.4636e-01, -2.3025e-01, -2.8819e-01, -5.0933e-02,  1.5410e-01,\n",
      "         2.4264e-01, -2.5172e-01,  1.9174e-04, -9.9205e-02,  1.6388e-01,\n",
      "         2.7838e-01,  3.6059e-02,  2.4476e-01, -2.6142e-02, -9.8026e-02,\n",
      "         4.0975e-02, -1.2300e-02,  2.0939e-02,  2.9014e-01, -1.4077e-02,\n",
      "         1.2432e-02,  1.3856e-01,  2.8813e-01,  1.6221e-01,  2.2897e-01,\n",
      "        -1.2940e-01,  1.1566e-01,  3.1792e-01, -5.1177e-02, -5.3571e-02,\n",
      "        -1.3136e-02, -1.1961e-01,  1.1482e-01, -3.5995e-01,  1.6752e-01,\n",
      "         3.1283e-01,  5.0011e-02, -9.7707e-02, -1.4806e-01, -2.8938e-01,\n",
      "         6.5292e-02, -4.2507e-01, -9.7796e-02,  1.0599e-02, -4.3252e-01,\n",
      "        -1.4716e-01,  2.2601e-01, -2.9080e-01, -6.4693e-02, -8.8255e-02,\n",
      "        -1.4038e-01, -2.4373e-01, -2.7446e-02, -5.9459e-02,  1.6791e-01,\n",
      "         1.9064e-01, -6.8592e-02,  2.9498e-01,  1.0716e-01, -1.4211e-01,\n",
      "         1.1423e-01, -8.7853e-02, -3.0187e-02, -2.3567e-01,  1.5005e-02,\n",
      "        -3.3678e-01,  3.1306e-01,  1.2327e-01,  7.5491e-02,  1.7918e-01,\n",
      "         4.1535e-01,  3.0707e-02, -2.3660e-01, -1.2451e-01,  3.7360e-01,\n",
      "        -3.7314e-03,  1.6130e-01,  1.6039e-01,  1.3808e-01, -1.1907e-01,\n",
      "        -2.9525e-01, -1.3972e-03, -8.7628e-02, -3.1920e-01,  8.0721e-02,\n",
      "         1.2992e-01, -1.8879e-01, -1.4365e-01, -2.6420e-01,  2.7948e-01,\n",
      "        -3.1325e-01, -3.1210e-01,  8.6516e-02, -1.4904e-01, -1.2620e-01,\n",
      "        -2.8936e-02,  9.8424e-03, -3.8972e-01,  9.6838e-02, -1.0259e-01,\n",
      "         2.2958e-01,  9.4769e-02,  1.3355e-01, -4.9172e-02,  5.0044e-02,\n",
      "        -1.1777e-01,  1.1754e-01, -3.1222e-01, -1.4836e-01, -6.5217e-03,\n",
      "         2.3025e-02, -7.8066e-02, -2.9517e-01,  7.2238e-02, -5.0224e-01,\n",
      "        -2.7947e-01, -4.1454e-02, -2.1372e-01, -3.2918e-01, -2.9042e-01,\n",
      "        -1.6204e-01,  2.2174e-01,  1.6513e-01, -4.3361e-02,  4.0081e-01,\n",
      "        -2.0874e-02,  1.3773e-01, -2.7313e-02,  1.3564e-01,  3.0688e-01,\n",
      "         3.8625e-01, -2.7886e-01,  4.4714e-01,  1.5051e-01, -2.1194e-01,\n",
      "        -5.3755e-02,  4.1791e-01,  1.1181e-01, -3.2676e-02, -6.5123e-02,\n",
      "        -2.8204e-01, -2.6390e-02, -1.5878e-01, -1.8864e-01, -1.7043e-01,\n",
      "         3.3488e-02, -3.9160e-02, -1.8230e-02,  4.5087e-02, -2.1513e-01,\n",
      "        -1.5099e-01,  7.3571e-02, -2.5957e-01,  2.3856e-01,  1.0418e-01,\n",
      "         5.8569e-02,  1.7587e-01,  3.3833e-01,  6.2456e-02, -2.2702e-01,\n",
      "        -1.8128e-01,  6.9963e-02,  1.8651e-01,  6.8224e-02,  3.0269e-01,\n",
      "         1.4332e-01,  2.3153e-02,  1.1075e-01, -1.7693e-01, -8.4791e-02,\n",
      "        -2.9128e-01, -3.1417e-01,  1.7378e-01, -5.9755e-02,  4.8584e-02,\n",
      "        -4.3335e-01, -3.2707e-01, -3.3093e-01, -4.1834e-02, -2.3795e-01,\n",
      "        -2.1745e-01, -5.5495e-03, -1.9234e-01, -6.7178e-02,  1.9833e-01,\n",
      "         6.7605e-02,  1.5820e-02,  1.9504e-01, -1.7985e-01, -1.4272e-01,\n",
      "        -7.6840e-02, -8.5874e-02,  7.9072e-02, -1.2802e-01,  1.6943e-02,\n",
      "         1.0812e-01,  3.7972e-02, -1.0098e-01,  2.2178e-01, -1.7382e-01,\n",
      "        -7.7719e-02, -9.0236e-03, -7.6289e-02,  2.9753e-02,  2.4059e-01,\n",
      "         4.1623e-02, -3.8450e-01,  1.1105e-01,  2.9108e-02, -2.8629e-02,\n",
      "        -1.2368e-01,  3.5504e-01,  3.0761e-01, -8.8533e-02,  3.4731e-01,\n",
      "         1.9733e-01,  9.4244e-02,  2.7051e-01,  1.3245e-01, -1.2150e-01,\n",
      "         7.9978e-02, -3.5653e-02,  5.8475e-02, -1.2765e-01,  1.2833e-02,\n",
      "         4.2913e-01,  1.9258e-02, -8.0236e-02,  4.8793e-02, -4.7800e-02,\n",
      "         6.1837e-02,  1.3274e-01,  4.1427e-01, -6.6180e-02,  2.3442e-01,\n",
      "         2.3002e-01, -3.0441e-01,  1.9936e-01,  2.4699e-01,  1.4671e-01,\n",
      "        -1.1490e-02, -1.6551e-01, -7.1447e-02, -2.5199e-01,  5.8576e-02,\n",
      "         5.4769e-02,  6.7709e-02,  1.3869e-01,  8.4448e-02,  1.7161e-01,\n",
      "        -3.0403e-01,  1.0160e-01,  3.3872e-02, -2.3301e-01, -5.7483e-01,\n",
      "         8.7209e-02,  1.8891e-01,  3.7089e-02,  2.8231e-04,  3.3224e-02,\n",
      "         2.5757e-02, -1.5252e-01, -8.9037e-02, -2.5921e-02, -1.4674e-01,\n",
      "        -2.0196e-01,  3.8148e-01, -1.5369e-01, -2.5197e-01,  1.0134e-01,\n",
      "         3.7183e-01, -2.4617e-02, -2.1708e-02, -5.7915e-02,  8.1800e-02,\n",
      "        -2.0689e-01, -4.2623e-02,  2.3613e-01,  1.3404e-01,  2.0069e-01,\n",
      "        -1.1863e-01,  2.1573e-01, -2.2985e-02, -9.4923e-02, -7.0852e-02,\n",
      "         1.6355e-01,  5.2138e-01,  1.9029e-01,  2.7812e-01,  2.7057e-01,\n",
      "         6.6904e-02, -3.1853e-02,  6.9797e-02, -1.3128e-01,  1.2680e-01,\n",
      "        -5.3896e-02,  1.8312e-01,  2.6878e-01,  4.1120e-02,  2.3616e-01,\n",
      "         2.4690e-02,  7.8031e-02, -1.4698e-01,  1.7977e-01, -1.5109e-01,\n",
      "        -3.1158e-03, -1.7498e-02, -1.9925e-01,  2.9763e-01, -1.1993e-01,\n",
      "         3.1039e-01,  3.0325e-02, -7.1839e-02,  1.6844e-01,  3.0963e-02,\n",
      "         6.5475e-02, -1.1279e-01, -1.0049e-01,  2.7037e-01,  1.3709e-01,\n",
      "        -2.3853e-01,  5.1139e-02, -2.1304e-01,  5.6159e-02,  1.7681e-01,\n",
      "         5.1935e-02, -6.4803e-02,  1.1393e-02,  9.4601e-02, -1.0355e-02,\n",
      "        -1.1778e-01,  1.7872e-01,  2.1844e-01, -8.8161e-02, -1.5362e-02,\n",
      "         3.9839e-02,  2.8122e-01, -2.8630e-01,  4.5639e-02, -7.6167e-02,\n",
      "         1.3211e-01,  3.4164e-01, -1.3276e-02, -9.5245e-02, -2.7231e-01,\n",
      "         1.0393e-01,  3.7037e-01,  3.1410e-01,  3.9537e-01,  2.5727e-01,\n",
      "        -8.1413e-02, -6.8823e-02, -1.2212e-01, -2.4686e-01, -7.2378e-02,\n",
      "        -2.6575e-02, -6.1189e-02, -3.5684e-02,  1.1527e-01, -2.1738e-01,\n",
      "        -1.2731e-02, -3.2326e-02, -9.1194e-02, -3.9108e-01, -2.7514e-02,\n",
      "         8.7509e-02, -1.7601e-01, -1.0190e-01, -1.2654e-01, -1.1505e-01,\n",
      "         1.8956e-01, -1.5143e-01,  6.4929e-03, -4.8972e-01,  1.6348e-01,\n",
      "         2.7129e-01,  7.5873e-02,  1.7874e-01, -3.0621e-02,  1.4500e-01,\n",
      "         2.4241e-01, -1.8688e-01,  6.9088e-02, -1.2447e-01, -1.8668e-01,\n",
      "         5.0031e-01,  1.0002e-01,  2.1749e-01, -3.1632e-01, -3.4786e-01,\n",
      "         5.4173e-02, -8.1316e-02, -1.3507e-01,  1.1496e-01,  4.7155e-02,\n",
      "        -1.5175e-02, -2.5641e-01, -4.1264e-01,  1.4672e-02, -1.2180e-01,\n",
      "        -1.4263e-02,  1.2324e-01,  1.3433e-01, -4.2392e-03, -4.5185e-01,\n",
      "        -2.0916e-02,  5.3411e-01,  6.7506e-02,  7.3651e-02, -3.7903e-01,\n",
      "        -1.8407e-01, -1.0280e-01,  7.2593e-02,  3.3384e-01,  2.6345e-01,\n",
      "         5.0855e-01, -2.0045e-01, -4.3925e-01, -2.9658e-01,  2.5365e-01,\n",
      "        -2.2366e-01,  2.7753e-01, -2.5177e-01, -2.2020e-01,  1.6649e-01,\n",
      "        -2.1910e-01,  5.2088e-01,  5.1263e-02,  3.2101e-02, -1.8151e-01,\n",
      "         4.4053e-01, -1.4172e-01,  2.6340e-02,  3.0689e-01,  4.9108e-02,\n",
      "        -1.4935e-01, -7.1719e-02,  1.2120e-02, -7.7538e-03, -9.6774e-02,\n",
      "         4.7434e-01, -2.4250e-01, -2.1478e-01,  7.2085e-02, -6.3996e-01,\n",
      "         2.0204e-01,  2.4910e-01,  1.6833e-01, -2.5249e-01,  7.8989e-02,\n",
      "         4.8758e-02, -2.8939e-01, -2.1178e-01, -2.1028e-02,  2.3238e-02,\n",
      "         5.8175e-02, -1.2643e-01,  5.4828e-02,  1.9774e-01,  4.1115e-01,\n",
      "         4.7827e-01,  1.0536e-01,  7.5241e-02, -3.1371e-01, -2.6448e-01,\n",
      "         6.5077e-02,  4.7854e-01,  2.6262e-02, -7.6053e-02, -9.8766e-02,\n",
      "         2.6315e-01,  5.2443e-01, -2.9881e-02,  5.7478e-02, -1.5235e-01,\n",
      "         1.7123e-01, -4.2773e-01, -2.2507e-02, -3.1681e-01,  1.8854e-01,\n",
      "         3.5689e-01,  1.7986e-01,  3.0416e-01,  1.8118e-01,  5.3570e-02,\n",
      "        -8.7452e-02, -2.3187e-01, -1.3026e-01, -6.2274e-01, -2.5709e-01,\n",
      "        -1.1582e-01, -2.5724e-01, -7.4312e-02, -1.9189e-01,  1.0474e-01,\n",
      "         1.5135e-01,  6.4216e-02,  9.6548e-02, -4.4886e-01,  2.2669e-01,\n",
      "        -4.0789e-01, -2.7166e-01, -7.8952e-02,  3.3108e-01, -9.3846e-02,\n",
      "        -1.1497e-01,  2.6521e-01, -2.6109e-01, -4.8006e-02, -1.0574e-01,\n",
      "        -4.3151e-01, -4.9388e-01, -1.9976e-01,  3.2416e-01,  8.8542e-02,\n",
      "         4.6222e-02,  1.6191e-01,  2.9278e-01, -3.8414e-02, -1.6170e-01,\n",
      "         1.1796e-01, -1.9552e-02, -1.6843e-01, -4.4195e-01, -5.8067e-02,\n",
      "         1.6425e-01,  1.0858e-01, -1.1904e-01, -2.3380e-01, -2.0853e-01,\n",
      "         1.1032e-01, -4.4938e-02,  8.1410e-02, -7.8388e-02,  2.8703e-02,\n",
      "         6.0680e-01, -2.3658e-01, -1.3142e-01])\n",
      "Embedding for emoji 'âœ…': tensor([ 4.4842e-03, -3.4699e-02,  4.9339e-02, -2.3820e-02, -8.4550e-02,\n",
      "         2.2517e-02,  1.3924e-02, -1.1351e-03,  2.9871e-02,  1.0317e-02,\n",
      "        -3.6027e-03, -2.0174e-02, -6.0324e-02,  5.8075e-03, -7.9424e-02,\n",
      "        -5.6046e-02,  7.1508e-02, -2.4246e-02, -3.0990e-02, -5.6461e-02,\n",
      "         3.1181e-02, -1.6569e-02,  6.0585e-02, -6.6918e-02,  1.5744e-02,\n",
      "         6.5908e-02,  2.8744e-02,  3.0687e-02, -4.8799e-02, -4.9141e-02,\n",
      "        -9.4362e-02, -6.8377e-03, -5.3215e-03,  2.6184e-02, -5.6410e-02,\n",
      "        -4.4340e-02, -5.5302e-03, -2.7456e-02, -9.2778e-02,  2.9942e-02,\n",
      "        -6.3287e-02,  8.4322e-03, -7.7724e-02, -9.9704e-03,  2.0489e-02,\n",
      "         4.0959e-02,  6.3462e-03, -5.5982e-02,  4.5110e-02,  5.5400e-02,\n",
      "        -2.2779e-02, -1.8955e-02,  4.2585e-02, -2.6068e-02, -1.6843e-02,\n",
      "         9.3047e-03, -2.5019e-02, -4.5929e-02,  1.9618e-02, -2.0853e-02,\n",
      "         3.1766e-02,  5.6927e-02,  4.8910e-02, -1.3960e-02, -4.0081e-02,\n",
      "        -8.2838e-02,  9.0526e-03, -4.2121e-02, -5.1070e-02, -9.9506e-03,\n",
      "         8.8807e-03, -7.2664e-02, -3.8734e-02,  9.9345e-02, -4.1996e-02,\n",
      "        -9.6840e-03, -1.0584e-02, -2.1598e-04,  1.5106e-02,  2.7209e-02,\n",
      "         8.0269e-02,  2.6005e-02,  3.1568e-02,  2.0664e-02, -5.2288e-02,\n",
      "        -4.8642e-02,  4.3396e-02,  4.7991e-02, -1.6968e-02, -5.6431e-02,\n",
      "         1.7487e-02, -2.7377e-02,  1.2912e-02, -6.5672e-02, -3.3421e-02,\n",
      "         1.4992e-02, -3.9583e-02,  2.1478e-02, -7.8319e-02,  8.1932e-02,\n",
      "         2.4923e-02,  5.1967e-02, -3.0753e-02, -1.2997e-02, -1.9859e-02,\n",
      "         3.8423e-02,  5.9311e-02,  3.5665e-02,  1.0373e-02,  3.6004e-04,\n",
      "         8.8889e-02,  6.5897e-02, -1.9300e-02,  1.9899e-02, -1.7536e-02,\n",
      "        -8.8250e-03, -2.4781e-03, -1.0053e-02,  6.0735e-02, -2.9924e-02,\n",
      "        -4.8074e-02, -7.3681e-02,  3.3850e-03,  3.6425e-02,  5.2970e-02,\n",
      "        -1.1595e-01, -2.0517e-02,  3.7935e-02, -1.1456e-01,  9.0704e-02,\n",
      "         4.1072e-02, -2.6048e-02, -1.1289e-03, -9.1798e-02, -2.8633e-02,\n",
      "        -1.0553e-03, -6.2695e-02,  4.6160e-02, -6.3872e-02, -7.1610e-02,\n",
      "        -1.3234e-02,  6.8032e-02, -1.8601e-02, -1.9077e-02, -9.2803e-02,\n",
      "         4.4177e-02, -5.0206e-02,  6.0081e-02,  4.7003e-02,  2.6948e-02,\n",
      "        -5.7222e-02, -3.1923e-02,  6.0732e-02, -3.5410e-02, -6.7853e-02,\n",
      "         2.7734e-02,  1.0515e-02, -5.7628e-04, -6.2135e-02,  3.4352e-03,\n",
      "        -5.3999e-02,  2.7505e-02,  8.2284e-02,  2.6242e-02,  5.0058e-02,\n",
      "         2.4038e-02, -2.8437e-02,  1.6274e-02,  1.1226e-02,  3.4658e-02,\n",
      "         1.8420e-02,  7.4395e-02,  5.1757e-02, -1.0873e-02, -9.3362e-02,\n",
      "         1.0897e-02,  9.4213e-02,  1.9156e-02,  3.7555e-02,  6.0786e-02,\n",
      "        -3.9208e-02, -9.6211e-03, -4.6213e-02, -4.2991e-02, -2.2299e-02,\n",
      "        -3.4888e-02, -6.1244e-02,  6.3632e-02,  2.7128e-02, -6.1033e-03,\n",
      "         3.7016e-02, -1.8519e-02,  9.9094e-02,  5.8578e-02, -1.4728e-02,\n",
      "         4.2443e-02, -7.0258e-02, -6.7877e-02,  3.6861e-02, -3.2107e-02,\n",
      "        -2.5098e-02, -8.7580e-03, -4.6276e-02,  1.8477e-02,  4.2404e-02,\n",
      "         5.6952e-02,  2.6537e-02,  9.1689e-02, -1.9296e-02,  3.8427e-03,\n",
      "         8.5960e-02, -1.1680e-02, -4.8978e-02, -6.3766e-02,  7.1116e-02,\n",
      "         1.7700e-02,  3.1861e-02, -2.8623e-02, -4.5908e-02,  4.3078e-03,\n",
      "        -1.3364e-02, -5.5515e-02, -6.7394e-02,  3.4843e-02,  5.4775e-02,\n",
      "        -5.9926e-02,  7.3901e-02, -2.4054e-02, -2.5064e-02,  4.8958e-02,\n",
      "         2.9896e-02, -5.4757e-02, -7.0701e-02, -7.3838e-02, -9.6906e-02,\n",
      "         3.7618e-02, -1.2819e-02,  1.4423e-02,  4.0706e-03,  2.6003e-02,\n",
      "        -2.3122e-02,  3.4403e-02, -5.5926e-03, -2.9824e-02, -1.5098e-02,\n",
      "         1.9463e-02, -1.2854e-02,  2.3286e-02, -4.8645e-02,  5.2301e-02,\n",
      "         8.3772e-02,  1.5525e-02,  9.2193e-03, -8.5096e-03, -1.7954e-02,\n",
      "        -2.7224e-02,  5.5010e-03,  9.1995e-02, -4.0117e-02,  5.0850e-02,\n",
      "        -1.0628e-02, -4.9817e-03, -4.5462e-02,  1.4175e-04,  1.2586e-02,\n",
      "        -8.1222e-03,  1.5741e-02,  1.9959e-02, -4.8105e-02,  5.9216e-02,\n",
      "        -6.5398e-02, -4.6986e-02, -6.5930e-02, -5.3698e-03,  4.0756e-02,\n",
      "        -3.3993e-02, -8.9055e-02, -2.5683e-02,  1.2872e-02,  2.1445e-02,\n",
      "        -2.7647e-02,  7.9122e-02, -1.4714e-03, -4.1752e-02,  6.3108e-02,\n",
      "        -2.8427e-02, -8.2197e-02, -6.4133e-02, -3.7167e-02,  3.9752e-02,\n",
      "        -1.2038e-02, -6.1707e-02,  2.9880e-02,  3.0003e-02, -1.4664e-02,\n",
      "        -2.6040e-02,  4.2478e-02,  1.4480e-02, -4.7665e-02, -9.4593e-02,\n",
      "        -4.5905e-02,  3.5169e-03, -2.8039e-02,  7.7602e-02, -8.4305e-02,\n",
      "         4.6467e-03,  1.9633e-03,  8.7301e-02, -2.2045e-02,  3.2253e-03,\n",
      "         3.9587e-02,  1.6018e-02,  3.0637e-02,  3.0851e-02, -3.9220e-02,\n",
      "         3.9927e-03, -4.0592e-02, -7.1451e-02, -1.2659e-03, -6.7624e-02,\n",
      "        -3.6796e-02,  1.1453e-01, -2.1902e-02,  4.2370e-02,  6.7520e-03,\n",
      "         6.4624e-02,  3.8686e-02,  1.0231e-02,  6.0045e-02,  1.7327e-03,\n",
      "        -3.6786e-02,  3.4697e-02,  1.1270e-02,  8.7577e-02,  8.7661e-02,\n",
      "         7.8573e-02,  4.7179e-02, -3.0321e-02, -6.3787e-02,  2.8368e-02,\n",
      "        -5.9740e-02,  4.1106e-02,  4.3648e-03,  1.2341e-02, -2.9965e-03,\n",
      "        -3.2833e-02, -1.0735e-02,  7.6456e-02, -2.7458e-02, -1.3408e-02,\n",
      "         3.0315e-02, -5.7828e-02,  9.9060e-03,  3.9155e-02,  6.4472e-03,\n",
      "         1.6597e-02,  1.2298e-02, -5.5764e-02,  5.7197e-02,  3.2546e-02,\n",
      "         3.2863e-02,  4.2230e-04,  6.5152e-02,  2.8604e-02,  6.0719e-02,\n",
      "        -2.5207e-02,  8.8031e-04, -1.3550e-02,  9.4928e-04, -6.7708e-02,\n",
      "        -3.0900e-02, -2.3812e-02,  6.4891e-02, -2.7649e-02, -2.2128e-02,\n",
      "        -2.6697e-02,  8.2529e-02,  2.0778e-02,  8.1116e-02, -5.9436e-02,\n",
      "        -4.1287e-02, -8.3490e-02, -2.8187e-02, -2.3037e-02,  5.0442e-02,\n",
      "         4.0524e-02, -5.6310e-03,  1.1674e-02,  9.7457e-03,  3.4352e-02,\n",
      "        -2.3289e-03, -9.8359e-02,  8.1176e-02, -6.4457e-02, -3.0202e-02,\n",
      "        -1.2766e-01, -2.9672e-02, -1.3468e-03,  8.7585e-03, -9.5691e-02,\n",
      "         2.9007e-02,  3.0824e-02, -2.3179e-02, -1.7353e-02,  6.9387e-02,\n",
      "        -5.8783e-04,  2.3407e-02, -3.9120e-02,  5.2607e-02, -2.3295e-02,\n",
      "         4.6575e-02,  6.2877e-02,  3.1723e-02, -7.1457e-02, -3.0441e-02,\n",
      "         1.4812e-02, -6.7489e-02, -7.5017e-02,  4.9046e-03,  2.5435e-02,\n",
      "         7.1823e-02,  4.0972e-03, -2.9431e-02,  2.7059e-02, -1.6415e-02,\n",
      "         5.7690e-03,  7.3687e-02, -2.5851e-03,  4.9577e-02, -5.5840e-02,\n",
      "         7.8337e-03,  4.6648e-02,  4.5512e-02, -8.0757e-02, -5.7355e-02,\n",
      "         1.1675e-02,  8.9713e-03,  5.8492e-03,  2.7093e-02, -7.1783e-03,\n",
      "        -5.6305e-02,  8.0813e-04,  4.7181e-03, -3.8376e-02, -3.7508e-02,\n",
      "         2.9935e-02,  1.0048e-02, -2.5917e-02, -7.1978e-02, -2.6628e-02,\n",
      "         3.4274e-02, -1.7295e-02, -2.4892e-02,  2.0404e-02, -4.0161e-02,\n",
      "        -3.7067e-03, -2.5270e-03, -1.3245e-02, -4.2739e-02, -6.4329e-03,\n",
      "        -4.1452e-02, -2.1648e-02, -3.7667e-02, -2.5844e-02,  3.0827e-03,\n",
      "         2.0581e-02, -2.1425e-02, -2.8636e-02,  1.3629e-02,  1.1720e-02,\n",
      "         2.9069e-02, -1.4758e-02, -3.0450e-03, -1.3931e-03,  6.5141e-02,\n",
      "         1.9568e-02, -1.2242e-02, -3.3422e-02,  3.1696e-02,  1.1901e-02,\n",
      "         3.4483e-02,  9.5475e-03, -9.8730e-03, -3.3798e-02,  8.3296e-02,\n",
      "        -6.0150e-02,  4.3611e-02,  5.5134e-02, -7.0851e-02, -1.1948e-01,\n",
      "         5.9400e-02,  2.9867e-02,  6.3402e-03, -6.1964e-02,  3.7092e-02,\n",
      "         3.1748e-02,  9.1511e-03, -3.5670e-02, -1.7589e-02, -1.0000e-01,\n",
      "         7.3178e-02, -3.4292e-02,  4.7812e-02,  8.8804e-02, -1.0890e-01,\n",
      "         1.2137e-02, -7.2998e-03, -1.7243e-02,  3.7348e-02,  3.1724e-03,\n",
      "        -2.3470e-02,  5.4816e-02,  5.0043e-02,  1.2127e-02, -5.5784e-02,\n",
      "        -9.1232e-02, -5.4100e-02,  8.5053e-02,  3.4035e-02, -6.2534e-02,\n",
      "        -2.3572e-02,  4.2734e-02,  2.1364e-02,  8.0078e-03,  1.9328e-02,\n",
      "         4.1926e-02,  1.0216e-01, -3.8941e-02,  2.6830e-02, -9.5626e-02,\n",
      "        -1.9976e-02,  1.2710e-02, -2.2692e-02,  4.0932e-02,  2.1029e-02,\n",
      "         3.3408e-02, -1.5667e-02,  3.1331e-02,  8.3512e-03,  1.7639e-02,\n",
      "         9.1501e-02, -1.7332e-02, -8.0174e-02, -1.7334e-02, -9.6795e-02,\n",
      "         6.8476e-02, -4.0500e-02,  3.0618e-02,  7.9382e-03,  5.0714e-02,\n",
      "         5.1089e-02,  3.9356e-02,  8.5941e-03, -1.9694e-03, -6.3430e-03,\n",
      "        -5.0726e-02, -4.4938e-02, -3.8924e-02, -7.8452e-02, -1.2544e-02,\n",
      "        -1.3246e-02, -5.1066e-02,  3.8072e-02,  1.0289e-01, -3.5151e-02,\n",
      "         8.2698e-02, -3.3010e-02,  4.9972e-02, -3.3900e-02,  1.0952e-01,\n",
      "         3.1855e-02, -6.2862e-02, -7.2084e-02, -1.1965e-01, -4.6440e-02,\n",
      "         7.6005e-02,  2.7148e-02, -1.1165e-01, -5.1416e-02,  4.2832e-02,\n",
      "        -2.0739e-02,  4.5687e-03,  4.8767e-02, -7.8913e-02,  3.2068e-02,\n",
      "         4.3209e-02, -1.6894e-02,  1.4448e-02,  2.5876e-02,  3.1705e-02,\n",
      "        -7.8674e-02,  6.7811e-02,  4.2759e-02, -8.6096e-02,  5.1115e-02,\n",
      "         1.4725e-02, -4.8062e-02,  1.9561e-02, -1.8675e-02, -5.9456e-06,\n",
      "        -3.7611e-02,  1.3742e-04, -4.7805e-02, -5.9771e-03, -1.0571e-01,\n",
      "         1.9815e-02,  2.0135e-02,  9.7482e-03,  5.6678e-02, -9.4788e-03,\n",
      "        -5.3501e-02, -9.4156e-02,  6.3121e-02,  1.0288e-01,  5.9793e-03,\n",
      "         2.3766e-02,  6.8098e-02, -6.1868e-02, -1.7429e-03,  6.5382e-02,\n",
      "        -4.3923e-02, -1.6680e-02, -3.4296e-02, -1.6517e-02, -1.1135e-01,\n",
      "        -3.4356e-02,  7.2167e-03,  6.0283e-02,  2.5374e-02, -5.6060e-02,\n",
      "        -4.7170e-02, -9.9658e-03, -2.0294e-02,  3.6857e-02, -2.9505e-02,\n",
      "         2.0238e-02, -2.8251e-02,  7.7799e-03,  7.6469e-02, -1.5440e-04,\n",
      "        -2.6678e-02, -2.3762e-02,  1.5836e-02, -6.1739e-02,  2.0577e-02,\n",
      "        -6.7360e-02, -4.9336e-02,  1.6949e-02, -7.5296e-03, -5.5755e-02,\n",
      "         6.1980e-02, -8.8979e-02,  5.4211e-02,  4.7678e-02,  9.0274e-02,\n",
      "         4.5483e-02, -1.4932e-02,  8.5663e-02,  4.6008e-02,  4.1522e-02,\n",
      "         2.6945e-02,  1.8548e-02, -5.5224e-02, -7.2499e-02, -1.4712e-02,\n",
      "        -5.5589e-02, -5.8810e-02, -7.4053e-02, -2.8040e-02, -4.2232e-02,\n",
      "         4.6180e-02,  4.5495e-02,  8.8943e-02,  4.0394e-02, -4.1870e-02,\n",
      "         1.2802e-01,  1.0729e-02, -4.3853e-02,  8.2534e-02,  3.6516e-02,\n",
      "         1.5218e-02,  6.3535e-03, -4.2928e-02, -3.8867e-02, -4.9197e-02,\n",
      "         7.7333e-02,  3.2580e-02,  9.8223e-02, -7.6913e-03,  8.5535e-02,\n",
      "         9.0141e-02,  6.9753e-03, -3.0403e-02, -6.7296e-02, -4.7683e-04,\n",
      "        -8.0104e-02, -6.5915e-02, -3.3281e-02,  1.8698e-02, -2.5100e-02,\n",
      "         7.2155e-02, -5.0049e-02, -8.9992e-02,  3.9940e-03,  5.9765e-02,\n",
      "        -7.8651e-02, -1.8069e-02,  4.2264e-02, -9.1001e-02,  6.4776e-02,\n",
      "         9.5008e-03, -2.7564e-02,  1.8269e-02, -7.2948e-02, -4.5054e-05,\n",
      "        -3.0786e-02,  3.7351e-02,  3.5298e-03,  5.9404e-02, -1.4543e-02,\n",
      "        -5.3669e-03,  2.3706e-04,  3.2456e-02, -4.6393e-02, -6.8914e-02,\n",
      "         1.6637e-02,  4.1559e-02,  3.4016e-03,  3.1472e-02,  1.3133e-02,\n",
      "         9.1619e-02,  2.8606e-02, -1.3384e-02, -1.7732e-02, -3.9139e-02,\n",
      "        -2.3455e-02,  3.8867e-02,  6.7737e-02, -4.9277e-02, -2.8680e-02,\n",
      "         7.0602e-03,  1.0125e-02, -7.0643e-02, -2.1518e-02, -7.2115e-02,\n",
      "        -2.8005e-02,  2.9404e-02,  5.2213e-03,  6.7226e-02, -4.3142e-02,\n",
      "         1.2977e-02,  5.2435e-02,  9.8760e-03,  1.7183e-02,  9.3038e-02,\n",
      "         7.8749e-02,  7.9727e-02,  5.6512e-02,  6.1734e-02,  4.0138e-02,\n",
      "         3.7787e-02, -5.4172e-02, -3.6472e-02, -5.4300e-02,  3.0862e-02,\n",
      "         1.9713e-02, -2.1069e-03, -4.6072e-02])\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = newModel.embeddings.word_embeddings\n",
    "\n",
    "if slang_id != tokenizer.unk_token_id:\n",
    "    slang_embedding = embedding_layer.weight.data[slang_id]\n",
    "    print(f\"Embedding for slang '{test_slang}': {slang_embedding}\")\n",
    "\n",
    "if emoji_id != tokenizer.unk_token_id:\n",
    "    emoji_embedding = embedding_layer.weight.data[emoji_id]\n",
    "    print(f\"Embedding for emoji '{test_emoji}': {emoji_embedding}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
