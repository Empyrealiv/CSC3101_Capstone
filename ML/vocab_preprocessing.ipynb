{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- awww, that's a bummer.  you shoulda got davi...</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his facebook by ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i dived many times for the ball. managed to sa...</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no, it's not behaving at all. i'm mad. why am ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196816</th>\n",
       "      <td>best viet hoagies you'll find in the area, or ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196817</th>\n",
       "      <td>if you need medical testing of any kind, i wou...</td>\n",
       "      <td>1</td>\n",
       "      <td>Yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196818</th>\n",
       "      <td>this place is a dream. honestly my favorite in...</td>\n",
       "      <td>1</td>\n",
       "      <td>Yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196819</th>\n",
       "      <td>great place to have your dog groom. my one dog...</td>\n",
       "      <td>1</td>\n",
       "      <td>Yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196820</th>\n",
       "      <td>this salon is great! the pedicure was great, g...</td>\n",
       "      <td>1</td>\n",
       "      <td>Yelp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2196821 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  polarity   source\n",
       "0        - awww, that's a bummer.  you shoulda got davi...         0  Twitter\n",
       "1        is upset that he can't update his facebook by ...         0  Twitter\n",
       "2        i dived many times for the ball. managed to sa...         0  Twitter\n",
       "3           my whole body feels itchy and like its on fire         0  Twitter\n",
       "4        no, it's not behaving at all. i'm mad. why am ...         0  Twitter\n",
       "...                                                    ...       ...      ...\n",
       "2196816  best viet hoagies you'll find in the area, or ...         1     Yelp\n",
       "2196817  if you need medical testing of any kind, i wou...         1     Yelp\n",
       "2196818  this place is a dream. honestly my favorite in...         1     Yelp\n",
       "2196819  great place to have your dog groom. my one dog...         1     Yelp\n",
       "2196820  this salon is great! the pedicure was great, g...         1     Yelp\n",
       "\n",
       "[2196821 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Datasets/Cleaned with tokens/combined_dataset.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slang dataset and TFIDF extraction\n",
    "\n",
    "https://huggingface.co/datasets/MLBtrio/genz-slang-dataset/viewer/default/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "slang_dataset = load_dataset(\"MLBtrio/genz-slang-dataset\")\n",
    "slang_words = [entry['Slang'] for entry in slang_dataset['train'] if ' ' not in entry['Slang'] and entry['Slang'].isalpha()]\n",
    "slang_words_set = set(word.lower() for word in slang_words)\n",
    "slang_words_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slang_tokenizer(text):\n",
    "    tokens = word_tokenize(text.lower(), language='english', preserve_line=True)\n",
    "    return [word for word in tokens if word.isalpha() and word in slang_words_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=slang_tokenizer, lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = vectorizer.fit_transform(data['text'])\n",
    "\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "tfidf_df.index = data.index\n",
    "\n",
    "slang_scores = tfidf_df.sum(axis=0).sort_values(ascending=False)\n",
    "slang_scores.to_csv('Vocabulary/slang_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Testing tokenizer detection of slang words\n",
    "words = [\"u\", \"im\", \"wat\", 'lmao', 'lol', 'brb', 'omg', 'wtf', 'smh', 'idk', 'tbh', 'sry']\n",
    "for word in words:\n",
    "    token_id = tokenizer.convert_tokens_to_ids(word)\n",
    "    if token_id == 100:  # ID 100 corresponds to the [UNK] token\n",
    "        print(f\"'{word}' is NOT in the BERT vocabulary (mapped to [UNK]).\")\n",
    "    else:\n",
    "        print(f\"'{word}' is in the BERT vocabulary with ID {token_id}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for slang score distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Slang</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>was</td>\n",
       "      <td>217339.246501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>so</td>\n",
       "      <td>165827.902975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>at</td>\n",
       "      <td>165670.348117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>are</td>\n",
       "      <td>156590.391256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>we</td>\n",
       "      <td>143283.229747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>nrn</td>\n",
       "      <td>0.642039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>iaaa</td>\n",
       "      <td>0.632667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>mirl</td>\n",
       "      <td>0.600004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>fbm</td>\n",
       "      <td>0.572891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>nfw</td>\n",
       "      <td>0.457322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>932 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Slang          Score\n",
       "0     was  217339.246501\n",
       "1      so  165827.902975\n",
       "2      at  165670.348117\n",
       "3     are  156590.391256\n",
       "4      we  143283.229747\n",
       "..    ...            ...\n",
       "927   nrn       0.642039\n",
       "928  iaaa       0.632667\n",
       "929  mirl       0.600004\n",
       "930   fbm       0.572891\n",
       "931   nfw       0.457322\n",
       "\n",
       "[932 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slang_score_distribution = pd.read_csv('Vocabulary/slang_scores.csv', header=None, names=['Slang', 'Score'])\n",
    "slang_score_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slang scores above 0: 932\n",
      "Slang scores above 50: 428\n",
      "Slang scores above 100: 353\n",
      "Slang scores above 1000: 108\n",
      "Slang scores above 10000: 15\n"
     ]
    }
   ],
   "source": [
    "print('Slang scores above 0: ' + str(slang_score_distribution[slang_score_distribution['Score'] > 0]['Score'].count()))\n",
    "print('Slang scores above 50: ' + str(slang_score_distribution[slang_score_distribution['Score'] > 50]['Score'].count()))\n",
    "print('Slang scores above 100: ' + str(slang_score_distribution[slang_score_distribution['Score'] > 100]['Score'].count()))\n",
    "print('Slang scores above 1000: ' + str(slang_score_distribution[slang_score_distribution['Score'] > 1000]['Score'].count()))\n",
    "print('Slang scores above 10000: ' + str(slang_score_distribution[slang_score_distribution['Score'] > 10000]['Score'].count()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for example usage of the slang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Slang</th>\n",
       "      <th>TF-IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im</td>\n",
       "      <td>41467.735488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oh</td>\n",
       "      <td>35708.223269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u</td>\n",
       "      <td>34531.078095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bio</td>\n",
       "      <td>13142.782625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wow</td>\n",
       "      <td>11133.654649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>pov</td>\n",
       "      <td>46.223900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>bcos</td>\n",
       "      <td>42.637456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>gtfo</td>\n",
       "      <td>41.713035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>gratz</td>\n",
       "      <td>34.687383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>rotfl</td>\n",
       "      <td>33.691888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>229 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Slang        TF-IDF\n",
       "0       im  41467.735488\n",
       "1       oh  35708.223269\n",
       "2        u  34531.078095\n",
       "3      bio  13142.782625\n",
       "4      wow  11133.654649\n",
       "..     ...           ...\n",
       "224    pov     46.223900\n",
       "225   bcos     42.637456\n",
       "226   gtfo     41.713035\n",
       "227  gratz     34.687383\n",
       "228  rotfl     33.691888\n",
       "\n",
       "[229 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slang_samples = pd.read_csv('Vocabulary/slang_scores_sample.csv', header=0, names=['Slang', 'TF-IDF'])\n",
    "slang_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sentences_with_slang(df, slang, max_samples=3):\n",
    "    matching_sentences = []\n",
    "    for sentence in df[\"text\"]:\n",
    "        tokens = word_tokenize(sentence.lower())\n",
    "        if slang in tokens:\n",
    "            matching_sentences.append(sentence)\n",
    "        if len(matching_sentences) >= max_samples:\n",
    "            break\n",
    "    return matching_sentences\n",
    "\n",
    "results = {}\n",
    "\n",
    "column_list = slang_samples['Slang'].tolist()\n",
    "\n",
    "for slang in column_list:\n",
    "    sentences = find_sentences_with_slang(data, slang, max_samples=3)\n",
    "    if sentences:\n",
    "        results[slang] = sentences\n",
    "\n",
    "if results:\n",
    "    results_df = pd.DataFrame([\n",
    "        {\"Slang\": slang, \"Sentence\": sentence}\n",
    "        for slang, sentences in results.items()\n",
    "        for sentence in sentences\n",
    "    ])\n",
    "else:\n",
    "    print(\"No slang terms found in the dataset.\")\n",
    "\n",
    "results_df.to_csv('slang_sample_examples.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emoji TFIDF extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "\n",
    "emoji_df = data.copy()\n",
    "\n",
    "def extract_emojis(text):\n",
    "    return \" \".join([e['emoji'] for e in emoji.emoji_list(text)])\n",
    "\n",
    "emoji_df[\"emojis\"] = data[\"text\"].apply(extract_emojis)\n",
    "emoji_df[\"emojis\"] = emoji_df[\"emojis\"].replace(\"\", \"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>source</th>\n",
       "      <th>emojis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- awww, that's a bummer.  you shoulda got davi...</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his facebook by ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i dived many times for the ball. managed to sa...</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no, it's not behaving at all. i'm mad. why am ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196816</th>\n",
       "      <td>best viet hoagies you'll find in the area, or ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Yelp</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196817</th>\n",
       "      <td>if you need medical testing of any kind, i wou...</td>\n",
       "      <td>1</td>\n",
       "      <td>Yelp</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196818</th>\n",
       "      <td>this place is a dream. honestly my favorite in...</td>\n",
       "      <td>1</td>\n",
       "      <td>Yelp</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196819</th>\n",
       "      <td>great place to have your dog groom. my one dog...</td>\n",
       "      <td>1</td>\n",
       "      <td>Yelp</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196820</th>\n",
       "      <td>this salon is great! the pedicure was great, g...</td>\n",
       "      <td>1</td>\n",
       "      <td>Yelp</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2196821 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  polarity   source  \\\n",
       "0        - awww, that's a bummer.  you shoulda got davi...         0  Twitter   \n",
       "1        is upset that he can't update his facebook by ...         0  Twitter   \n",
       "2        i dived many times for the ball. managed to sa...         0  Twitter   \n",
       "3           my whole body feels itchy and like its on fire         0  Twitter   \n",
       "4        no, it's not behaving at all. i'm mad. why am ...         0  Twitter   \n",
       "...                                                    ...       ...      ...   \n",
       "2196816  best viet hoagies you'll find in the area, or ...         1     Yelp   \n",
       "2196817  if you need medical testing of any kind, i wou...         1     Yelp   \n",
       "2196818  this place is a dream. honestly my favorite in...         1     Yelp   \n",
       "2196819  great place to have your dog groom. my one dog...         1     Yelp   \n",
       "2196820  this salon is great! the pedicure was great, g...         1     Yelp   \n",
       "\n",
       "        emojis  \n",
       "0         none  \n",
       "1         none  \n",
       "2         none  \n",
       "3         none  \n",
       "4         none  \n",
       "...        ...  \n",
       "2196816   none  \n",
       "2196817   none  \n",
       "2196818   none  \n",
       "2196819   none  \n",
       "2196820   none  \n",
       "\n",
       "[2196821 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    lowercase=False,\n",
    "    token_pattern=r\"[^\\s]+\"  # Match any non-whitespace characters (e.g., emojis)\n",
    ")\n",
    "\n",
    "tfidf_matrix = vectorizer.fit_transform(emoji_df[\"emojis\"])\n",
    "\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "tfidf_df.index = emoji_df.index\n",
    "\n",
    "emoji_scores = tfidf_df.sum(axis=0).sort_values(ascending=False)\n",
    "\n",
    "emoji_scores.to_csv(\"Vocabulary/emoji_scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emoji</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‚ù§</td>\n",
       "      <td>4378.094343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‚úÖ</td>\n",
       "      <td>4073.393400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>üò∑</td>\n",
       "      <td>2764.420312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>üëâ</td>\n",
       "      <td>2686.821333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‚ú®</td>\n",
       "      <td>2266.170048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>üèÑüèæ</td>\n",
       "      <td>0.109644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>üí±</td>\n",
       "      <td>0.095398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>üëßüèø</td>\n",
       "      <td>0.093676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1728</th>\n",
       "      <td>üèäüèæ</td>\n",
       "      <td>0.038994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>üëºüèæ</td>\n",
       "      <td>0.020936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1730 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Emoji        Score\n",
       "0        ‚ù§  4378.094343\n",
       "1        ‚úÖ  4073.393400\n",
       "2        üò∑  2764.420312\n",
       "3        üëâ  2686.821333\n",
       "4        ‚ú®  2266.170048\n",
       "...    ...          ...\n",
       "1725    üèÑüèæ     0.109644\n",
       "1726     üí±     0.095398\n",
       "1727    üëßüèø     0.093676\n",
       "1728    üèäüèæ     0.038994\n",
       "1729    üëºüèæ     0.020936\n",
       "\n",
       "[1730 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_scores_distribution = pd.read_csv('Vocabulary/emoji_scores.csv', header=None, names=['Emoji', 'Score'])\n",
    "emoji_scores_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emoji scores above 0: 1730\n",
      "Emoji scores above 50: 348\n",
      "Emoji scores above 100: 228\n",
      "Emoji scores above 1000: 16\n",
      "Emoji scores above 10000: 0\n"
     ]
    }
   ],
   "source": [
    "print('Emoji scores above 0: ' + str(emoji_scores_distribution[emoji_scores_distribution['Score'] > 0]['Score'].count()))\n",
    "print('Emoji scores above 50: ' + str(emoji_scores_distribution[emoji_scores_distribution['Score'] > 50]['Score'].count()))\n",
    "print('Emoji scores above 100: ' + str(emoji_scores_distribution[emoji_scores_distribution['Score'] > 100]['Score'].count()))\n",
    "print('Emoji scores above 1000: ' + str(emoji_scores_distribution[emoji_scores_distribution['Score'] > 1000]['Score'].count()))\n",
    "print('Emoji scores above 10000: ' + str(emoji_scores_distribution[emoji_scores_distribution['Score'] > 10000]['Score'].count()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
